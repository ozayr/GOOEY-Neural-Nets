{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "def valid_imshow_data(data):\n",
    "    data = np.asarray(data)\n",
    "    if data.ndim == 2:\n",
    "        return True\n",
    "    elif data.ndim == 3:\n",
    "        if 3 <= data.shape[2] <= 4:\n",
    "            return True\n",
    "        else:\n",
    "            print('The \"data\" has 3 dimensions but the last dimension '\n",
    "                  'must have a length of 3 (RGB) or 4 (RGBA), not \"{}\".'\n",
    "                  ''.format(data.shape[2]))\n",
    "            return False\n",
    "    else:\n",
    "        print('To visualize an image the data must be 2 dimensional or '\n",
    "              '3 dimensional, not \"{}\".'\n",
    "              ''.format(data.ndim))\n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1ddbad2d5214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcluster_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseDataset' is not defined"
     ]
    }
   ],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "        \n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    " \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.Tensor(self.X[i])\n",
    "        if self.clusters > 2:\n",
    "            y_data =  torch.Tensor([1 if self.y[i] == j else 0 for j in range(self.clusters)]).long()\n",
    "        else:\n",
    "            y_data = torch.Tensor([self.y[i]])\n",
    "#         print(y_data,self.y[i])\n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_viewable_image(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array( (0.5,0.5,0.5)) + np.array( (0.5,0.5,0.5))\n",
    "    image = image.clip(0,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdfb0039eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])\n",
    "training_dataset = datasets.MNIST(root = './data',train =True,download =True,transform=transform)\n",
    "validation_dataset = datasets.MNIST(root = './data',train =False,download =True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "    \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "            \n",
    "        pred = self.output_layer(x)\n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.detach().numpy(),axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class my_cnn_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1 , classses = 10,fc_neurons = 500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 20, 5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.FC = nn.Linear(800,fc_neurons)\n",
    "        self.head = nn.Linear(fc_neurons,classses)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "       \n",
    "       \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "    \n",
    "        x =x.view(-1,800)\n",
    "        \n",
    "        x = F.relu(self.FC(x))\n",
    "        x= self.dropout(x)\n",
    "        pred = self.head(x)\n",
    "        return pred\n",
    "    \n",
    "    def conv_output_size(self,image_size, kernal_size, padding = 0  , stride = 1):\n",
    "        w = image_size\n",
    "        k = kernal_size\n",
    "        p = padding\n",
    "        s = stride\n",
    "        return int(((w-k+2*p)/s)+1)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.cpu().detach().numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "training_loader = DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.resize(img, dim, interpolation = cv2.INTER_AREA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2048ede890>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = cv2.resize( to_viewable_image(training_dataset[0][0]) , (200,200), interpolation = cv2.INTER_AREA)\n",
    " \n",
    "plt.imshow(img) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = iter(training_loader).next()\n",
    "model = my_cnn_model()\n",
    "model.forward(X).shape\n",
    "# X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 training loss:0.2511  training accuracy:0.9243 val loss:0.0689  val accuracy:0.9784\n",
      "epoch:1 training loss:0.0636  training accuracy:0.9806 val loss:0.0475  val accuracy:0.9839\n",
      "epoch:2 training loss:0.0433  training accuracy:0.9862 val loss:0.0447  val accuracy:0.9859\n",
      "epoch:3 training loss:0.0353  training accuracy:0.9892 val loss:0.0407  val accuracy:0.9878\n",
      "epoch:4 training loss:0.0294  training accuracy:0.9907 val loss:0.037  val accuracy:0.9897\n",
      "epoch:5 training loss:0.0247  training accuracy:0.9923 val loss:0.0347  val accuracy:0.989\n",
      "epoch:6 training loss:0.0229  training accuracy:0.9927 val loss:0.0377  val accuracy:0.9885\n",
      "epoch:7 training loss:0.0192  training accuracy:0.994 val loss:0.0304  val accuracy:0.9912\n",
      "epoch:8 training loss:0.0169  training accuracy:0.9945 val loss:0.0343  val accuracy:0.9909\n",
      "epoch:9 training loss:0.0164  training accuracy:0.9947 val loss:0.0311  val accuracy:0.9914\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model = my_model(input_size = 28*28 ,output_size = 10, num_layers = 2, width = 100)\n",
    "model = my_cnn_model().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "epochs = 10\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss =[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    training_running_loss = 0.0\n",
    "    training_running_accuracy =0.0\n",
    "    \n",
    "    validation_running_loss = 0.0\n",
    "    validation_running_accuracy =0.0\n",
    "    \n",
    "    for X,y in training_loader:\n",
    "        \n",
    "        X,y = X.to(device),y.to(device) \n",
    "#         X = X.view(X.shape[0],-1)\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_running_loss += loss.item()\n",
    "        \n",
    "        predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "        training_running_accuracy += sum(predicted_label == y.cpu().data)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for val_X,val_y in validation_loader:\n",
    "\n",
    "                val_X,val_y = val_X.to(device),val_y.to(device) \n",
    "#                 val_X = val_X.view(val_X.shape[0],-1)\n",
    "                y_pred = model(val_X)\n",
    "                loss = criterion(y_pred,val_y)\n",
    "                \n",
    "                validation_running_loss += loss.item()\n",
    "                predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "                validation_running_accuracy += sum(predicted_label == val_y.cpu().data)\n",
    "                \n",
    "                \n",
    "            \n",
    "        val_epoch_loss = validation_running_loss/len(validation_loader)\n",
    "        val_epoch_accuracy = (validation_running_accuracy.float()/len(validation_loader))/batch_size\n",
    "        \n",
    "        epoch_loss = training_running_loss/len(training_loader)\n",
    "        epoch_accuracy = (training_running_accuracy.float()/len(training_loader))/batch_size\n",
    "        \n",
    "        print(f'epoch:{i} training loss:{ round(epoch_loss,4) }  training accuracy:{ round(epoch_accuracy.item(),4) } val loss:{ round(val_epoch_loss,4) }  val accuracy:{ round(val_epoch_accuracy.item(),4) }')\n",
    "        \n",
    "        training_loss.append(epoch_loss)\n",
    "        training_accuracy.append(epoch_accuracy.item())\n",
    "        \n",
    "        validation_loss.append(val_epoch_loss)\n",
    "        validation_accuracy.append(val_epoch_accuracy.item())\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  plt.figure()\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "ax1.plot(training_loss , label = 'train')\n",
    "ax1.plot(validation_loss , label = 'val')\n",
    "ax1.set_title('loss')\n",
    "ax1.legend()\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "ax2.plot(training_accuracy , label = 'train')\n",
    "ax2.plot(validation_accuracy , label = 'val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('wDropout.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "\n",
    "drawing = False # true if mouse is pressed\n",
    "pt1_x , pt1_y = None , None\n",
    "\n",
    "\n",
    "def show(img, title=\"\", time=-1):\n",
    "    cv2.imshow(title, img)\n",
    "    key = cv2.waitKey(time)\n",
    "    return key\n",
    "\n",
    "def draw_digit(model):\n",
    "    # mouse callback function\n",
    "    def line_drawing(event,x,y,flags,param):\n",
    "        global pt1_x,pt1_y,drawing\n",
    "\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing=True\n",
    "            pt1_x,pt1_y=x,y\n",
    "\n",
    "        elif event==cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing==True:\n",
    "                cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)\n",
    "                pt1_x,pt1_y=x,y\n",
    "        elif event==cv2.EVENT_LBUTTONUP:\n",
    "            drawing=False\n",
    "            cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)        \n",
    "\n",
    "\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    cv2.namedWindow('test draw')\n",
    "    cv2.setMouseCallback('test draw',line_drawing)\n",
    "\n",
    "    whil1:\n",
    "        key = show(img,'test draw',1)\n",
    "        if key == 13:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    digit = digit.convert('1')\n",
    "    digit = transform(digit)\n",
    "    # digit = digit.view(digit.shape[0],-1)\n",
    "    digit = digit.unsqueeze(0).to(device)\n",
    "    y_pred = model(digit)\n",
    "    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "    \n",
    "    \n",
    "    return img\n",
    "\n",
    "digit  = Image.fromarray(draw_digit())\n",
    "digit = digit.convert('1')\n",
    "digit = transform(digit)\n",
    "# digit = digit.view(digit.shape[0],-1)\n",
    "digit = digit.unsqueeze(0).to(device)\n",
    "y_pred = model(digit)\n",
    "predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQuUlEQVR4nO3bbWjV9f/H8dc2Tyl5Rc4Izjm5gZuesRsT2+adcLFiTFi7YZLLSGtsrpiBN2KQN3IEQUVJkIQcAtOUtSJy4MQSNRTcOLAL53TrHDvSOY3Ci/ROhUs+/xs/Gu2/i+9x23vbyecD3jfOzmdf34p7cvbdToYkJwAwkDnXCwD47yIwAMwQGABmCAwAMwQGgBkCA8CMZ2A+++wz/fbbb+rr65vwzMcff6xoNKre3l6tW7duRhcEkN7cZPPUU0+5devWub6+vnGfr6ysdO3t7U6SKy0tdR0dHZNej2GYB2c8X8GcO3dOt27dmvD56upqHTp0SJLU2dmp5cuX6/HHH/e6LIAHwILpXsDv9yuRSIw8TiaT8vv9+vXXX8ecraurU319vSRpzZo1GhwcnO4fD2AWrFq1So899th9f960A5ORkTHmY865cc+Gw2GFw2FJUiQSUXFx8XT/eACzIBKJTOnzpv1TpGQyqWAwOPI4EAhoaGhoupcF8B8w7cC0tbXp5ZdfliSVlpbqzp074357BODB4/kt0tGjR1VWVqbs7GwlEgm9/fbb8vl8kqQDBw6ovb1dmzZtUiwW0x9//KFXXnnFfGkA6cEzMC+++KLnRRobG2dkGQD/LfwmLwAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZlIKTEVFhQYGBhSNRtXU1DTm+WAwqNOnT6urq0u9vb2qrKyc8UUBpCc32WRmZrpYLOZyc3Odz+dzPT09LhQKjTpz4MAB19DQ4CS5UCjk4vH4pNeU5CKRiOcZhmHmx0z169XzFUxJSYlisZji8biGh4fV0tKi6urqUWecc1q6dKkkadmyZRoaGvK6LIAHwAKvA36/X4lEYuRxMplUaWnpqDN79+7Vd999p127dumRRx7RM888M+616urqVF9fL0nKzs6ezt4A0oDnK5iMjIwxH3POjXpcU1OjgwcPKhgMatOmTTp8+PC4nxcOh1VcXKzi4mLduHFjGmsDSAeegUkmkwoGgyOPA4HAmG+Bamtr1draKknq6OjQwoULeYUCwDswkUhEeXl5ysnJkc/n09atW9XW1jbqzM8//6zy8nJJ0tq1a7Vw4UJdv37dZmMAacXzTnBlZaUbHBx0sVjMvfXWW06Sa25udlVVVU7630+Ozp8/73p6elx3d7d79tlnze5KMwwz+zONr9e0W5hhmFkesx9TA8BUERgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmEkpMBUVFRoYGFA0GlVTU9O4Z7Zs2aL+/n5dunRJR44cmdElAaQvN9lkZma6WCzmcnNznc/ncz09PS4UCo06s3r1atfV1eWWL1/uJLmVK1dOek1JLhKJeJ5hGGZ+zFS/Xj1fwZSUlCgWiykej2t4eFgtLS2qrq4edaaurk779+/X7du3JUnXr1/3uiyAB4BnYPx+vxKJxMjjZDIpv98/6kx+fr7y8/N1/vx5XbhwQRUVFTO/KYC0s8DrQEZGxpiPOedGX2TBAuXl5amsrEyBQEDnzp1TYWGh7ty5M+pcXV2d6uvrJUnZ2dnT2RtAGvB8BZNMJhUMBkceBwIBDQ0NjTlz7Ngx/f3337p27ZoGBweVl5c35lrhcFjFxcUqLi7WjRs3ZmB9APOZZ2AikYjy8vKUk5Mjn8+nrVu3qq2tbdSZb7/9Vk8//bQkacWKFcrPz9dPP/1kszGAtOEZmHv37qmxsVEnT57UlStX1NraqsuXL6u5uVlVVVWSpJMnT+rmzZvq7+/XmTNn9Oabb+rWrVvmywOY/9Lqx14Mw8z+mP2YGgCmisAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwExKgamoqNDAwICi0aiampomPLd582Y557R+/foZWxBA+vIMTGZmpvbv36/KykoVFBSopqZGoVBozLnFixfrjTfeUEdHh8miANKPZ2BKSkoUi8UUj8c1PDyslpYWVVdXjzn3zjvv6P3339dff/1lsiiA9OMZGL/fr0QiMfI4mUzK7/ePOlNUVKRgMKjjx4/P/IYA0tYCrwMZGRljPuacG/X8vn37tGPHDs8/rK6uTvX19ZKk7Ozs+1gTQDryfAWTTCYVDAZHHgcCAQ0NDY08XrJkiQoLC3X27FnF43Ft2LBBbW1t497oDYfDKi4uVnFxsW7cuDFDfwUA85mbbLKystzVq1ddTk6O8/l8rqenxxUUFEx4/syZM279+vWTXlOSi0QinmcYhpkfM9WvV89XMPfu3VNjY6NOnjypK1euqLW1VZcvX1Zzc7Oqqqq8Ph3AAy6tisgwzOyP2SsYAJgqAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgJmUAlNRUaGBgQFFo1E1NTWNeX737t3q7+9Xb2+vTp06pSeeeGLGFwWQntxkk5mZ6WKxmMvNzXU+n8/19PS4UCg06kxZWZlbtGiRk+QaGhpcS0vLpNeU5CKRiOcZhmHmx0z169XzFUxJSYlisZji8biGh4fV0tKi6urqUWfOnj2rP//8U5LU0dGhQCDgdVkADwDPwPj9fiUSiZHHyWRSfr9/wvO1tbU6ceLEuM/V1dUpEokoEokoOzt7CusCSCcLvA5kZGSM+Zhzbtyz27Zt05NPPqmNGzeO+3w4HFY4HJYkRSKR+9kTQBryDEwymVQwGBx5HAgENDQ0NOZceXm59uzZo40bN+ru3bszuyWAtDXpTZqsrCx39epVl5OTM3KTt6CgYNSZoqIiF4vF3OrVq81vGjEMM/tjdpP33r17amxs1MmTJ3XlyhW1trbq8uXLam5uVlVVlSTpgw8+0OLFi/XVV1+pu7tbx44d87osgAdEWhWRYZjZH7NXMAAwVQQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGYIDAAzBAaAGQIDwAyBAWCGwAAwQ2AAmCEwAMwQGABmCAwAMwQGgBkCA8AMgQFghsAAMENgAJghMADMEBgAZggMADMEBoAZAgPADIEBYIbAADBDYACYITAAzBAYAGZSCkxFRYUGBgYUjUbV1NQ05vmHHnpILS0tikaj6ujo0KpVq2Z8UQDpxzMwmZmZ2r9/vyorK1VQUKCamhqFQqFRZ2pra/X7778rLy9P+/bt03vvvWe2MID04RmYkpISxWIxxeNxDQ8Pq6WlRdXV1aPOVFdX6/PPP5ckff311yovL7fZFkBaWeB1wO/3K5FIjDxOJpMqLS2d8My9e/d0584drVixQjdv3hx1rq6uTvX19ZKkwsJCRSKRaf8F5kJ2drZu3Lgx12tMCbvPnXTef82aNVP6PM/AZGRkjPmYc+6+z0hSOBxWOByWJEUiERUXF6e86HzC7nMjnXeX0nv/qb4Y8PwWKZlMKhgMjjwOBAIaGhqa8ExWVpaWLVumW7duTWkhAP8dnoGJRCLKy8tTTk6OfD6ftm7dqra2tlFn2tratH37dknS888/r9OnT9tsCyCtZEnaO9kB55yi0aiOHDmiXbt26YsvvtA333yj5uZmLVmyRD/++KMuXryobdu26d1331VRUZEaGhp0+/Ztzz+8q6trhv4as4/d50Y67y6l9/5T2T1D0tibJQAwA/hNXgBmCAwAM+aBSee3GXjtvnv3bvX396u3t1enTp3SE088MQdbjs9r939s3rxZzjmtX79+FrebXCq7b9myRf39/bp06ZKOHDkyyxtOzGv3YDCo06dPq6urS729vaqsrJyDLcf32Wef6bffflNfX9+EZz7++GNFo1H19vZq3bp1KV3XWU1mZqaLxWIuNzfX+Xw+19PT40Kh0Kgzr732mvv000+dJPfCCy+4lpYWs31meveysjK3aNEiJ8k1NDSk1e6S3OLFi90PP/zgLly44NavXz/ne6e6++rVq11XV5dbvny5k+RWrlw553unuvuBAwdcQ0ODk+RCoZCLx+Nzvvc/89RTT7l169a5vr6+cZ+vrKx07e3tTpIrLS11HR0d3v8mMpTObzNIZfezZ8/qzz//lCR1dHQoEAjMxapjpLK7JL3zzjt6//339ddff83BluNLZfe6ujrt379/5CeV169fn4tVx0hld+ecli5dKklatmzZmN8pm0vnzp2b9PfXqqurdejQIUlSZ2enli9frscff3zSa5oGZry3Gfj9/gnP/PttBnMtld3/rba2VidOnJiN1TylsntRUZGCwaCOHz8+2+tNKpXd8/PzlZ+fr/Pnz+vChQuqqKiY7TXHlcrue/fu1UsvvaREIqH29nbt2rVrttecsvv9mpBSeKvAdMzk2wxm2/3stW3bNj355JPauHGj9Vop8do9IyND+/bt044dO2Zxq9Sk8u++YMEC5eXlqaysTIFAQOfOnVNhYaHu3LkzW2uOK5Xda2pqdPDgQX300UfasGGDDh8+rMLCwnnxf97LVL5WTV/BpPPbDFLZXZLKy8u1Z88ePffcc7p79+5srjghr92XLFmiwsJCnT17VvF4XBs2bFBbW9u8uNGb6v+ZY8eO6e+//9a1a9c0ODiovLy82V51jFR2r62tVWtrq6T/fVu9cOFCZWdnz+qeU5Xq18T/Z3bTKCsry129etXl5OSM3PQqKCgYdeb1118fdZP3yy+/nPObXanuXlRU5GKxmFu9evWc73u/u/97zpw5M29u8qaye0VFhTt48KCT5FasWOF+/vln9+ijj6bF7u3t7W779u1Oklu7dq375Zdf5nzvf8+qVasmvMm7adOmUTd5Ozs7U7mm7cKVlZVucHDQxWIx99ZbbzlJrrm52VVVVTlJ7uGHH3atra0uGo26zs5Ol5ubO+f/yKnu/v3337tff/3VdXd3u+7ubnfs2LE53znV3f898ykwqe7+4Ycfuv7+fnfx4kX3wgsvzPnOqe4eCoXc+fPnXU9Pj+vu7nbPPvvsnO/8zxw9etQNDQ25u3fvukQi4V599VW3c+dOt3PnzpEzn3zyiYvFYu7ixYsp/Z/hrQIAzPCbvADMEBgAZggMADMEBoAZAgPADIEBYIbAADDzf2mRxWrAeQM9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('dark_background')\n",
    "sg.theme('Black')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])\n",
    "training_dataset = datasets.MNIST(root = './data',train =True,download =True,transform=transform)\n",
    "validation_dataset = datasets.MNIST(root = './data',train =False,download =True,transform=transform)\n",
    "    \n",
    "\n",
    "drawing = False # true if mouse is pressed\n",
    "pt1_x , pt1_y = None , None\n",
    "\n",
    "\n",
    "def preview_data():\n",
    "    for i in range(0,5):\n",
    "        j = np.random.randint(0,1000)\n",
    "        img = cv2.resize( to_viewable_image(training_dataset[j][0]) , (200,200), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imshow('', img)\n",
    "        cv2.waitKey(1000)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def to_viewable_image(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array( (0.5,0.5,0.5)) + np.array( (0.5,0.5,0.5))\n",
    "    image = image.clip(0,1)\n",
    "    return image\n",
    "    \n",
    "def show(img, title=\"\", time=-1):\n",
    "    cv2.imshow(title, img)\n",
    "    key = cv2.waitKey(time)\n",
    "    return key\n",
    "\n",
    "def draw_digit(model):\n",
    "    # mouse callback function\n",
    "    def line_drawing(event,x,y,flags,param):\n",
    "        global pt1_x,pt1_y,drawing\n",
    "\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing=True\n",
    "            pt1_x,pt1_y=x,y\n",
    "\n",
    "        elif event==cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing==True:\n",
    "                cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)\n",
    "                pt1_x,pt1_y=x,y\n",
    "        elif event==cv2.EVENT_LBUTTONUP:\n",
    "            drawing=False\n",
    "            cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)        \n",
    "\n",
    "\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    cv2.namedWindow('Hand Written Digit Classifier:Press enter to classify')\n",
    "    cv2.setMouseCallback('Hand Written Digit Classifier:Press enter to classify',line_drawing)\n",
    "\n",
    "    while 1:\n",
    "        key = show(img,'Hand Written Digit Classifier:Press enter to classify',1)\n",
    "        if key == 13:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('1')\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    y_pred = model(img)\n",
    "    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "    pads = '*'*10\n",
    "    sg.popup(f'{pads}You drew:{predicted_label.numpy()[0]}{pads}',background_color='yellow',text_color='black',title = 'Prediction' )\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class my_cnn_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1 , classses = 10,fc_neurons = 500,dropout_on = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 20, 5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.FC = nn.Linear(800,fc_neurons)\n",
    "        self.head = nn.Linear(fc_neurons,classses)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout_on = dropout_on\n",
    "        \n",
    "    def forward(self,x):\n",
    "       \n",
    "       \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "    \n",
    "        x =x.view(-1,800)\n",
    "        \n",
    "        x = F.relu(self.FC(x))\n",
    "        \n",
    "        if self.dropout_on:\n",
    "            x= self.dropout(x)\n",
    "        \n",
    "        pred = self.head(x)\n",
    "        return pred\n",
    "    \n",
    "    def conv_output_size(self,image_size, kernal_size, padding = 0  , stride = 1):\n",
    "        w = image_size\n",
    "        k = kernal_size\n",
    "        p = padding\n",
    "        s = stride\n",
    "        return int(((w-k+2*p)/s)+1)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.cpu().detach().numpy(),axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "try:\n",
    "    model = my_cnn_model().to(device)\n",
    "except:\n",
    "    device = torch.device('cpu')\n",
    "    model = my_cnn_model().to(device)   \n",
    "    \n",
    "    \n",
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    return figure_canvas_agg\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if (v.default is not inspect.Parameter.empty) and (k != 'lr')\n",
    "    }\n",
    "\n",
    "\n",
    "def train_network(net_fig_queue,stop_training_queue ):\n",
    " \n",
    "    \n",
    "\n",
    "    neurons = int(values['neuron_slider'] )\n",
    "    dropout_on = values['dropout']\n",
    "    learning_rate = float(values['lr_slider']) \n",
    "    epochs = int(values['epoch_slider'])\n",
    "    batch_size = int(values['batch_slider'])\n",
    "    \n",
    "    training_loader = DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=False)\n",
    "    global model\n",
    "    model = my_cnn_model(dropout_on = dropout_on).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "\n",
    "    validation_accuracy = []\n",
    "    validation_loss =[]\n",
    "    \n",
    "    train_inc = (len(training_loader.dataset)/batch_size)//100\n",
    "    val_inc = (len(validation_loader.dataset)/batch_size)//100\n",
    "    for i in range(epochs):\n",
    "\n",
    "        training_running_loss = 0.0\n",
    "        training_running_accuracy =0.0\n",
    "\n",
    "        validation_running_loss = 0.0\n",
    "        validation_running_accuracy =0.0\n",
    "        train_count = 0\n",
    "       \n",
    "        for X,y in training_loader:\n",
    "\n",
    "            X,y = X.to(device),y.to(device) \n",
    "    #         X = X.view(X.shape[0],-1)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            try:\n",
    "                train_terminate = stop_training_queue.get_nowait()\n",
    "            except queue.Empty:\n",
    "                train_terminate = None\n",
    "            finally:\n",
    "                if train_terminate:\n",
    "                    return \n",
    "             \n",
    "            training_running_loss += loss.item()\n",
    "\n",
    "            predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "            training_running_accuracy += sum(predicted_label == y.cpu().data)\n",
    "#             Progress bar training\n",
    "            \n",
    "           \n",
    "            if train_count % train_inc == 0:    \n",
    "                window['train_bar'].UpdateBar(train_count//train_inc)\n",
    "            train_count += 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(train_count)\n",
    "            with torch.no_grad():\n",
    "                val_count = 0\n",
    "                for val_X,val_y in validation_loader:\n",
    "                    \n",
    "                    try:\n",
    "                        train_terminate = stop_training_queue.get_nowait()\n",
    "                    except queue.Empty:\n",
    "                        train_terminate = None\n",
    "                    finally:\n",
    "                        if train_terminate:\n",
    "                            return\n",
    "                    \n",
    "                    \n",
    "                    val_X,val_y = val_X.to(device),val_y.to(device) \n",
    "    #                 val_X = val_X.view(val_X.shape[0],-1)\n",
    "                    y_pred = model(val_X)\n",
    "                    loss = criterion(y_pred,val_y)\n",
    "\n",
    "                    validation_running_loss += loss.item()\n",
    "                    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "                    validation_running_accuracy += sum(predicted_label == val_y.cpu().data)\n",
    "                    if val_count % val_inc == 0:\n",
    "                        window['val_bar'].UpdateBar(val_count//val_inc)\n",
    "                    val_count += 1\n",
    "# progress bar validating\n",
    "\n",
    "\n",
    "            val_epoch_loss = validation_running_loss/len(validation_loader)\n",
    "            val_epoch_accuracy = (validation_running_accuracy.float()/len(validation_loader))/batch_size\n",
    "\n",
    "            epoch_loss = training_running_loss/len(training_loader)\n",
    "            epoch_accuracy = (training_running_accuracy.float()/len(training_loader))/batch_size\n",
    "\n",
    "            print(f'epoch:{i} training loss:{ round(epoch_loss,4) }  training accuracy:{ round(epoch_accuracy.item(),4) } val loss:{ round(val_epoch_loss,4) }  val accuracy:{ round(val_epoch_accuracy.item(),4) }')\n",
    "            \n",
    "            window['epoch_bar'].UpdateBar((i+1)*(100/epochs))\n",
    "            \n",
    "            training_loss.append(epoch_loss)\n",
    "            training_accuracy.append(epoch_accuracy.item())\n",
    "\n",
    "            validation_loss.append(val_epoch_loss)\n",
    "            validation_accuracy.append(val_epoch_accuracy.item())\n",
    "            \n",
    "            net_plot.cla()\n",
    "            net_plot.set_title('Loss')\n",
    "            net_plot.plot(training_loss,label = 'train')\n",
    "            net_plot.plot(validation_loss,label = 'Val')\n",
    "            net_plot.legend()\n",
    "            loss_plot.cla()\n",
    "            loss_plot.set_title('Accuracy')\n",
    "            loss_plot.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            loss_plot.plot(training_accuracy , label = 'train')\n",
    "            loss_plot.plot(validation_accuracy, label = 'val' )\n",
    "            loss_plot.legend()\n",
    "            \n",
    "            net_fig_queue.put(1)\n",
    "            \n",
    "        \n",
    "\n",
    "    window['stop_training'].update(disabled = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_len= len('GOOEY Neural Nets: Convolutional Neural Networks')\n",
    "data_frame_text_len = len('Number of clusters:')\n",
    "model_frame_text_len = len('Number of neurons in FC layer:')\n",
    "bar_format = len('Training:')\n",
    "\n",
    "optimizer_list = [optimizer for optimizer in  dir(torch.optim) if (optimizer not in ['Optimizer','lr_scheduler']) and ('__' not in optimizer  ) ]\n",
    "max_optim_len = max([len(string) for string in optimizer_list]) + 1\n",
    "optimizer_parameter_dict = {optimizer:get_default_args(getattr(torch.optim,optimizer)) for optimizer in optimizer_list }\n",
    "initial_optim_params_list = list( optimizer_parameter_dict[optimizer_list[0]] )\n",
    "init_params_dict = optimizer_parameter_dict[optimizer_list[0]]\n",
    "max_optim_len = max([len(string) for string in optimizer_list])\n",
    "\n",
    "\n",
    "layout = [\n",
    "\n",
    "    [sg.Text('GOOEY Neural Nets: Convolutional Neural Networks', size=(text_len, 1), justification='center', font=(\"Arial\", 25), relief=sg.RELIEF_RIDGE)],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Button('Preview Data')],\n",
    "       \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'DATA'  )   ],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Number of neurons in FC layer:',size = (model_frame_text_len,1) ),sg.Slider(default_value = 500, range=(100, 1000), size=(60, 20), orientation='h', key='neuron_slider')     ],\n",
    "        [sg.Text('activate dropout:',size = (model_frame_text_len,1)),sg.Checkbox('',key='dropout')],\n",
    "        [sg.Text('Batch Size:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 32,range=(32, 500),resolution=1, size=(60, 20), orientation='h', key='batch_slider')    ],\n",
    "        [sg.Text('Learning Rate:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 0.01,range=(0, 10),resolution=0.01, size=(60, 20), orientation='h', key='lr_slider')    ],\n",
    "        [sg.Text('Epochs:',size = (model_frame_text_len,1)),sg.Slider(default_value = 15,range=(0, 100),resolution=1, size=(60, 20), orientation='h', key='epoch_slider')     ],\n",
    "        [sg.Text('Optimizers:',size = (model_frame_text_len,1)),sg.DropDown(values = optimizer_list , default_value = optimizer_list[0],enable_events = True, key = 'optimizer',size = (max_optim_len,1))],\n",
    "        [sg.Text('Optimizer parameters:',size = (model_frame_text_len,1)), sg.DropDown(values = initial_optim_params_list, default_value = initial_optim_params_list[0], enable_events = True  , key ='optimizer_params')],\n",
    "        [sg.Text('parameter value:',size = (model_frame_text_len,1)),sg.Input( init_params_dict[ initial_optim_params_list[0]],tooltip = 'Enter in format shown', key = 'param_value',size = (10,1)) , sg.Text(type(init_params_dict[ initial_optim_params_list[0]]),key='param_type' ) , sg.Button('Update',key = 'update') ,sg.Button('reset all',key = 'reset')]\n",
    "        \n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'MODEL'  )   ],\n",
    "    \n",
    "    [sg.Button('Start Training',key = 'train_net'),sg.Button('Stop Training' , disabled = True, key = 'stop_training') ],\n",
    "    [sg.Text('Training:',size=(bar_format,1)),sg.ProgressBar(100, orientation='h', size=(20, 20), key='train_bar'),sg.Text('Validating:'),sg.ProgressBar(100, orientation='h', size=(20, 20), key='val_bar')],\n",
    "    [sg.Text('Epochs:',size=(bar_format,1)),sg.ProgressBar(100, orientation='h', size=(20, 20), key='epoch_bar')],\n",
    "    [sg.Canvas( size = (100,100) , key = 'net_canvas' ),sg.Canvas( size = (100,100) , key = 'loss_canvas' )],\n",
    "    [sg.Button('Classify My Hand Written Digits',key = 'test')],\n",
    "    \n",
    "    [sg.Button('Exit')]\n",
    "]      \n",
    "\n",
    "window = sg.Window('GOOEY Neural Nets', layout , finalize = True) \n",
    "\n",
    "# net canvas\n",
    "net_canvas_elem = window['net_canvas']\n",
    "net_canvas = net_canvas_elem.TKCanvas\n",
    "\n",
    "net_fig = plt.figure(figsize=(4,4))\n",
    "net_plot = net_fig.add_subplot(111)\n",
    "# net_plot.grid()\n",
    "net_fig_agg = draw_figure(net_canvas, net_fig)\n",
    "\n",
    "# loss canvas\n",
    "loss_canvas_elem = window['loss_canvas']\n",
    "loss_canvas = loss_canvas_elem.TKCanvas\n",
    "\n",
    "loss_fig = plt.figure(figsize=(4,4))\n",
    "loss_plot = loss_fig.add_subplot(111)\n",
    "# loss_plot.grid()\n",
    "loss_fig_agg = draw_figure(loss_canvas, loss_fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "draw_signal = queue.Queue()\n",
    "stop_training = queue.Queue()\n",
    "\n",
    "# =======\n",
    " \n",
    "criterion = ''\n",
    "optimizer = ''\n",
    "epochs = ''\n",
    "\n",
    "losses = []\n",
    "\n",
    "data_points = 0\n",
    "data = ''\n",
    "#===========\n",
    "while 1:\n",
    "    event, values = window.read(timeout = 100)    \n",
    "    if event == 'Exit':\n",
    "        stop_training.put(1)\n",
    "        window.close()\n",
    "        break\n",
    "    elif event == 'Preview Data':\n",
    "        preview_data()\n",
    "        \n",
    "    elif event == 'optimizer':\n",
    "        \n",
    "         window['optimizer_params'].update( values= list( optimizer_parameter_dict[ values['optimizer'] ] ) ) \n",
    "\n",
    "    elif event == 'optimizer_params':\n",
    "        \n",
    "        current_param_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']])\n",
    "        window['param_type'].update(current_param_type if current_param_type != int else float)\n",
    "        param_value = optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']]\n",
    "        window['param_value'].update( param_value if current_param_type != int else float(param_value) )\n",
    "       \n",
    "        \n",
    "    elif event == 'update':\n",
    "        current_param_type = type( optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] )\n",
    "        new_value = ''\n",
    "        if current_param_type == tuple:\n",
    "            indiv_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']][0])\n",
    "            if len(values['param_value'].split()) != 2:\n",
    "                print('incorrect input')\n",
    "            else:\n",
    "                new_value = ( indiv_type(values['param_value'].split()[0]) , indiv_type(values['param_value'].split()[1]) )\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "        else:\n",
    "            try:\n",
    "                new_value = current_param_type(values['param_value'])\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "            except:\n",
    "                print('incorrect input')\n",
    "                   \n",
    "    elif event == 'train_net':\n",
    "        net_plot.cla()\n",
    "        loss_plot.cla()\n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        window['train_bar'].UpdateBar(0)\n",
    "        window['val_bar'].UpdateBar(0)\n",
    "        window['epoch_bar'].UpdateBar(0)\n",
    "        t1 = threading.Thread(target=train_network , args = (draw_signal,stop_training) , daemon = True)\n",
    "        t1.start()\n",
    "        window['stop_training'].update(disabled = False)\n",
    "        \n",
    "    elif event =='stop_training':  \n",
    "        stop_training.put(1)\n",
    "        window['stop_training'].update(disabled = True)\n",
    "    elif event =='test':\n",
    "        draw_digit(model)\n",
    "    \n",
    "            \n",
    "    try:\n",
    "        draw_status = draw_signal.get_nowait()\n",
    "    except queue.Empty:\n",
    "        draw_status = None\n",
    "    \n",
    "    if draw_status:\n",
    "        \n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
