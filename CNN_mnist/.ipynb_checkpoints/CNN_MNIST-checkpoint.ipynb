{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_viewable_image(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array( (0.5,0.5,0.5)) + np.array( (0.5,0.5,0.5))\n",
    "    image = image.clip(0,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])\n",
    "training_dataset = datasets.MNIST(root = './data',train =True,download =True,transform=transform)\n",
    "validation_dataset = datasets.MNIST(root = './data',train =False,download =True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "    \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "            \n",
    "        pred = self.output_layer(x)\n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.detach().numpy(),axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class my_cnn_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1 , classses = 10,fc_neurons = 500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 20, 5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.FC = nn.Linear(800,fc_neurons)\n",
    "        self.head = nn.Linear(fc_neurons,classses)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "       \n",
    "       \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "    \n",
    "        x =x.view(-1,800)\n",
    "        \n",
    "        x = F.relu(self.FC(x))\n",
    "        x= self.dropout(x)\n",
    "        pred = self.head(x)\n",
    "        return pred\n",
    "    \n",
    "    def conv_output_size(self,image_size, kernal_size, padding = 0  , stride = 1):\n",
    "        w = image_size\n",
    "        k = kernal_size\n",
    "        p = padding\n",
    "        s = stride\n",
    "        return int(((w-k+2*p)/s)+1)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.cpu().detach().numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "training_loader = DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model = my_model(input_size = 28*28 ,output_size = 10, num_layers = 2, width = 100)\n",
    "model = my_cnn_model().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "epochs = 10\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss =[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    training_running_loss = 0.0\n",
    "    training_running_accuracy =0.0\n",
    "    \n",
    "    validation_running_loss = 0.0\n",
    "    validation_running_accuracy =0.0\n",
    "    \n",
    "    for X,y in training_loader:\n",
    "        \n",
    "        X,y = X.to(device),y.to(device) \n",
    "#         X = X.view(X.shape[0],-1)\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_running_loss += loss.item()\n",
    "        \n",
    "        predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "        training_running_accuracy += sum(predicted_label == y.cpu().data)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for val_X,val_y in validation_loader:\n",
    "\n",
    "                val_X,val_y = val_X.to(device),val_y.to(device) \n",
    "#                 val_X = val_X.view(val_X.shape[0],-1)\n",
    "                y_pred = model(val_X)\n",
    "                loss = criterion(y_pred,val_y)\n",
    "                \n",
    "                validation_running_loss += loss.item()\n",
    "                predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "                validation_running_accuracy += sum(predicted_label == val_y.cpu().data)\n",
    "                \n",
    "                \n",
    "            \n",
    "        val_epoch_loss = validation_running_loss/len(validation_loader)\n",
    "        val_epoch_accuracy = (validation_running_accuracy.float()/len(validation_loader))/batch_size\n",
    "        \n",
    "        epoch_loss = training_running_loss/len(training_loader)\n",
    "        epoch_accuracy = (training_running_accuracy.float()/len(training_loader))/batch_size\n",
    "        \n",
    "        print(f'epoch:{i} training loss:{ round(epoch_loss,4) }  training accuracy:{ round(epoch_accuracy.item(),4) } val loss:{ round(val_epoch_loss,4) }  val accuracy:{ round(val_epoch_accuracy.item(),4) }')\n",
    "        \n",
    "        training_loss.append(epoch_loss)\n",
    "        training_accuracy.append(epoch_accuracy.item())\n",
    "        \n",
    "        validation_loss.append(val_epoch_loss)\n",
    "        validation_accuracy.append(val_epoch_accuracy.item())\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  plt.figure()\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "ax1.plot(training_loss , label = 'train')\n",
    "ax1.plot(validation_loss , label = 'val')\n",
    "ax1.set_title('loss')\n",
    "ax1.legend()\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "ax2.plot(training_accuracy , label = 'train')\n",
    "ax2.plot(validation_accuracy , label = 'val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('wDropout.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "\n",
    "drawing = False # true if mouse is pressed\n",
    "pt1_x , pt1_y = None , None\n",
    "\n",
    "\n",
    "def show(img, title=\"\", time=-1):\n",
    "    cv2.imshow(title, img)\n",
    "    key = cv2.waitKey(time)\n",
    "    return key\n",
    "\n",
    "def draw_digit(model):\n",
    "    # mouse callback function\n",
    "    def line_drawing(event,x,y,flags,param):\n",
    "        global pt1_x,pt1_y,drawing\n",
    "\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing=True\n",
    "            pt1_x,pt1_y=x,y\n",
    "\n",
    "        elif event==cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing==True:\n",
    "                cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)\n",
    "                pt1_x,pt1_y=x,y\n",
    "        elif event==cv2.EVENT_LBUTTONUP:\n",
    "            drawing=False\n",
    "            cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)        \n",
    "\n",
    "\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    cv2.namedWindow('test draw')\n",
    "    cv2.setMouseCallback('test draw',line_drawing)\n",
    "\n",
    "    whil1:\n",
    "        key = show(img,'test draw',1)\n",
    "        if key == 13:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('1')\n",
    "    img = transform(img)\n",
    "    # digit = digit.view(digit.shape[0],-1)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    y_pred = model(img)\n",
    "    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "    \n",
    "    \n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('dark_background')\n",
    "sg.theme('Black')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])\n",
    "training_dataset = datasets.MNIST(root = './data',train =True,download =True,transform=transform)\n",
    "validation_dataset = datasets.MNIST(root = './data',train =False,download =True,transform=transform)\n",
    "    \n",
    "\n",
    "drawing = False # true if mouse is pressed\n",
    "pt1_x , pt1_y = None , None\n",
    "\n",
    "\n",
    "def preview_data():\n",
    "    for i in range(0,5):\n",
    "        j = np.random.randint(0,1000)\n",
    "        img = cv2.resize( to_viewable_image(training_dataset[j][0]) , (200,200), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imshow('', img)\n",
    "        cv2.waitKey(1000)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def to_viewable_image(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array( (0.5,0.5,0.5)) + np.array( (0.5,0.5,0.5))\n",
    "    image = image.clip(0,1)\n",
    "    return image\n",
    "    \n",
    "def show(img, title=\"\", time=-1):\n",
    "    cv2.imshow(title, img)\n",
    "    key = cv2.waitKey(time)\n",
    "    return key\n",
    "\n",
    "def draw_digit(model):\n",
    "    # mouse callback function\n",
    "    def line_drawing(event,x,y,flags,param):\n",
    "        global pt1_x,pt1_y,drawing\n",
    "\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing=True\n",
    "            pt1_x,pt1_y=x,y\n",
    "\n",
    "        elif event==cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing==True:\n",
    "                cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)\n",
    "                pt1_x,pt1_y=x,y\n",
    "        elif event==cv2.EVENT_LBUTTONUP:\n",
    "            drawing=False\n",
    "            cv2.line(img,(pt1_x,pt1_y),(x,y),color=(255,255,255),thickness=20)        \n",
    "\n",
    "\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    cv2.namedWindow('Hand Written Digit Classifier:Press enter to classify')\n",
    "    cv2.setMouseCallback('Hand Written Digit Classifier:Press enter to classify',line_drawing)\n",
    "\n",
    "    while 1:\n",
    "        key = show(img,'Hand Written Digit Classifier:Press enter to classify',1)\n",
    "        if key == 13:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('1')\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    y_pred = model(img)\n",
    "    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "    pads = '*'*10\n",
    "    sg.popup(f'{pads}You drew:{predicted_label.numpy()[0]}{pads}',background_color='yellow',text_color='black',title = 'Prediction' )\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class my_cnn_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1 , classses = 10,fc_neurons = 500,dropout_on = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 20, 5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.FC = nn.Linear(800,fc_neurons)\n",
    "        self.head = nn.Linear(fc_neurons,classses)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout_on = dropout_on\n",
    "        \n",
    "    def forward(self,x):\n",
    "       \n",
    "       \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "    \n",
    "        x =x.view(-1,800)\n",
    "        \n",
    "        x = F.relu(self.FC(x))\n",
    "        \n",
    "        if self.dropout_on:\n",
    "            x= self.dropout(x)\n",
    "        \n",
    "        pred = self.head(x)\n",
    "        return pred\n",
    "    \n",
    "    def conv_output_size(self,image_size, kernal_size, padding = 0  , stride = 1):\n",
    "        w = image_size\n",
    "        k = kernal_size\n",
    "        p = padding\n",
    "        s = stride\n",
    "        return int(((w-k+2*p)/s)+1)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        return np.argmax(pred.cpu().detach().numpy(),axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "try:\n",
    "    model = my_cnn_model().to(device)\n",
    "except:\n",
    "    device = torch.device('cpu')\n",
    "    model = my_cnn_model().to(device)   \n",
    "    \n",
    "    \n",
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    return figure_canvas_agg\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if (v.default is not inspect.Parameter.empty) and (k != 'lr')\n",
    "    }\n",
    "\n",
    "\n",
    "def train_network(net_fig_queue,stop_training_queue ):\n",
    " \n",
    "    \n",
    "\n",
    "    neurons = int(values['neuron_slider'] )\n",
    "    dropout_on = values['dropout']\n",
    "    learning_rate = float(values['lr_slider']) \n",
    "    epochs = int(values['epoch_slider'])\n",
    "    batch_size = int(values['batch_slider'])\n",
    "    \n",
    "    training_loader = DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=False)\n",
    "    global model\n",
    "    model = my_cnn_model(dropout_on = dropout_on).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "\n",
    "    validation_accuracy = []\n",
    "    validation_loss =[]\n",
    "    \n",
    "    train_inc = (len(training_loader.dataset)/batch_size)//100\n",
    "    val_inc = (len(validation_loader.dataset)/batch_size)//100\n",
    "    for i in range(epochs):\n",
    "\n",
    "        training_running_loss = 0.0\n",
    "        training_running_accuracy =0.0\n",
    "\n",
    "        validation_running_loss = 0.0\n",
    "        validation_running_accuracy =0.0\n",
    "        train_count = 0\n",
    "       \n",
    "        for X,y in training_loader:\n",
    "\n",
    "            X,y = X.to(device),y.to(device) \n",
    "    #         X = X.view(X.shape[0],-1)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            try:\n",
    "                train_terminate = stop_training_queue.get_nowait()\n",
    "            except queue.Empty:\n",
    "                train_terminate = None\n",
    "            finally:\n",
    "                if train_terminate:\n",
    "                    return \n",
    "             \n",
    "            training_running_loss += loss.item()\n",
    "\n",
    "            predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "            training_running_accuracy += sum(predicted_label == y.cpu().data)\n",
    "#             Progress bar training\n",
    "            \n",
    "           \n",
    "            if train_count % train_inc == 0:    \n",
    "                window['train_bar'].UpdateBar(train_count//train_inc)\n",
    "            train_count += 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(train_count)\n",
    "            with torch.no_grad():\n",
    "                val_count = 0\n",
    "                for val_X,val_y in validation_loader:\n",
    "                    \n",
    "                    try:\n",
    "                        train_terminate = stop_training_queue.get_nowait()\n",
    "                    except queue.Empty:\n",
    "                        train_terminate = None\n",
    "                    finally:\n",
    "                        if train_terminate:\n",
    "                            return\n",
    "                    \n",
    "                    \n",
    "                    val_X,val_y = val_X.to(device),val_y.to(device) \n",
    "    #                 val_X = val_X.view(val_X.shape[0],-1)\n",
    "                    y_pred = model(val_X)\n",
    "                    loss = criterion(y_pred,val_y)\n",
    "\n",
    "                    validation_running_loss += loss.item()\n",
    "                    predicted_label = np.argmax(y_pred.cpu().detach(),1)\n",
    "                    validation_running_accuracy += sum(predicted_label == val_y.cpu().data)\n",
    "                    if val_count % val_inc == 0:\n",
    "                        window['val_bar'].UpdateBar(val_count//val_inc)\n",
    "                    val_count += 1\n",
    "# progress bar validating\n",
    "\n",
    "\n",
    "            val_epoch_loss = validation_running_loss/len(validation_loader)\n",
    "            val_epoch_accuracy = (validation_running_accuracy.float()/len(validation_loader))/batch_size\n",
    "\n",
    "            epoch_loss = training_running_loss/len(training_loader)\n",
    "            epoch_accuracy = (training_running_accuracy.float()/len(training_loader))/batch_size\n",
    "\n",
    "            print(f'epoch:{i} training loss:{ round(epoch_loss,4) }  training accuracy:{ round(epoch_accuracy.item(),4) } val loss:{ round(val_epoch_loss,4) }  val accuracy:{ round(val_epoch_accuracy.item(),4) }')\n",
    "            \n",
    "            window['epoch_bar'].UpdateBar((i+1)*(100/epochs))\n",
    "            \n",
    "            training_loss.append(epoch_loss)\n",
    "            training_accuracy.append(epoch_accuracy.item())\n",
    "\n",
    "            validation_loss.append(val_epoch_loss)\n",
    "            validation_accuracy.append(val_epoch_accuracy.item())\n",
    "            \n",
    "            net_plot.cla()\n",
    "            net_plot.set_title('Loss')\n",
    "            net_plot.plot(training_loss,label = 'train')\n",
    "            net_plot.plot(validation_loss,label = 'Val')\n",
    "            net_plot.legend()\n",
    "            loss_plot.cla()\n",
    "            loss_plot.set_title('Accuracy')\n",
    "            loss_plot.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            loss_plot.plot(training_accuracy , label = 'train')\n",
    "            loss_plot.plot(validation_accuracy, label = 'val' )\n",
    "            loss_plot.legend()\n",
    "            \n",
    "            net_fig_queue.put(1)\n",
    "            \n",
    "        \n",
    "\n",
    "    window['stop_training'].update(disabled = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_len= len('GOOEY Neural Nets: Convolutional Neural Networks')\n",
    "data_frame_text_len = len('Number of clusters:')\n",
    "model_frame_text_len = len('Number of neurons in FC layer:')\n",
    "bar_format = len('Training:')\n",
    "\n",
    "optimizer_list = [optimizer for optimizer in  dir(torch.optim) if (optimizer not in ['Optimizer','lr_scheduler']) and ('__' not in optimizer  ) ]\n",
    "max_optim_len = max([len(string) for string in optimizer_list]) + 1\n",
    "optimizer_parameter_dict = {optimizer:get_default_args(getattr(torch.optim,optimizer)) for optimizer in optimizer_list }\n",
    "initial_optim_params_list = list( optimizer_parameter_dict[optimizer_list[0]] )\n",
    "init_params_dict = optimizer_parameter_dict[optimizer_list[0]]\n",
    "max_optim_len = max([len(string) for string in optimizer_list])\n",
    "\n",
    "\n",
    "layout = [\n",
    "\n",
    "    [sg.Text('GOOEY Neural Nets: Convolutional Neural Networks', size=(text_len, 1), justification='center', font=(\"Arial\", 25), relief=sg.RELIEF_RIDGE)],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Button('Preview Data')],\n",
    "       \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'DATA'  )   ],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Number of neurons in FC layer:',size = (model_frame_text_len,1) ),sg.Slider(default_value = 500, range=(100, 1000), size=(60, 20), orientation='h', key='neuron_slider')     ],\n",
    "        [sg.Text('activate dropout:',size = (model_frame_text_len,1)),sg.Checkbox('',key='dropout')],\n",
    "        [sg.Text('Batch Size:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 32,range=(32, 500),resolution=1, size=(60, 20), orientation='h', key='batch_slider')    ],\n",
    "        [sg.Text('Learning Rate:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 0.01,range=(0, 10),resolution=0.01, size=(60, 20), orientation='h', key='lr_slider')    ],\n",
    "        [sg.Text('Epochs:',size = (model_frame_text_len,1)),sg.Slider(default_value = 15,range=(0, 100),resolution=1, size=(60, 20), orientation='h', key='epoch_slider')     ],\n",
    "        [sg.Text('Optimizers:',size = (model_frame_text_len,1)),sg.DropDown(values = optimizer_list , default_value = optimizer_list[0],enable_events = True, key = 'optimizer',size = (max_optim_len,1))],\n",
    "        [sg.Text('Optimizer parameters:',size = (model_frame_text_len,1)), sg.DropDown(values = initial_optim_params_list, default_value = initial_optim_params_list[0], enable_events = True  , key ='optimizer_params')],\n",
    "        [sg.Text('parameter value:',size = (model_frame_text_len,1)),sg.Input( init_params_dict[ initial_optim_params_list[0]],tooltip = 'Enter in format shown', key = 'param_value',size = (10,1)) , sg.Text(type(init_params_dict[ initial_optim_params_list[0]]),key='param_type' ) , sg.Button('Update',key = 'update') ,sg.Button('reset all',key = 'reset')]\n",
    "        \n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'MODEL'  )   ],\n",
    "    \n",
    "    [sg.Button('Start Training',key = 'train_net'),sg.Button('Stop Training' , disabled = True, key = 'stop_training') ],\n",
    "    [sg.Text('Training:',size=(bar_format,1)),sg.ProgressBar(100, orientation='h', size=(20, 20), key='train_bar'),sg.Text('Validating:'),sg.ProgressBar(100, orientation='h', size=(20, 20), key='val_bar')],\n",
    "    [sg.Text('Epochs:',size=(bar_format,1)),sg.ProgressBar(100, orientation='h', size=(20, 20), key='epoch_bar')],\n",
    "    [sg.Canvas( size = (100,100) , key = 'net_canvas' ),sg.Canvas( size = (100,100) , key = 'loss_canvas' )],\n",
    "    [sg.Button('Classify My Hand Written Digits',key = 'test')],\n",
    "    \n",
    "    [sg.Button('Exit')]\n",
    "]      \n",
    "\n",
    "window = sg.Window('GOOEY Neural Nets', layout , finalize = True) \n",
    "\n",
    "# net canvas\n",
    "net_canvas_elem = window['net_canvas']\n",
    "net_canvas = net_canvas_elem.TKCanvas\n",
    "\n",
    "net_fig = plt.figure(figsize=(4,4))\n",
    "net_plot = net_fig.add_subplot(111)\n",
    "# net_plot.grid()\n",
    "net_fig_agg = draw_figure(net_canvas, net_fig)\n",
    "\n",
    "# loss canvas\n",
    "loss_canvas_elem = window['loss_canvas']\n",
    "loss_canvas = loss_canvas_elem.TKCanvas\n",
    "\n",
    "loss_fig = plt.figure(figsize=(4,4))\n",
    "loss_plot = loss_fig.add_subplot(111)\n",
    "# loss_plot.grid()\n",
    "loss_fig_agg = draw_figure(loss_canvas, loss_fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "draw_signal = queue.Queue()\n",
    "stop_training = queue.Queue()\n",
    "\n",
    "# =======\n",
    " \n",
    "criterion = ''\n",
    "optimizer = ''\n",
    "epochs = ''\n",
    "\n",
    "losses = []\n",
    "\n",
    "data_points = 0\n",
    "data = ''\n",
    "#===========\n",
    "while 1:\n",
    "    event, values = window.read(timeout = 100)    \n",
    "    if event == 'Exit':\n",
    "        stop_training.put(1)\n",
    "        window.close()\n",
    "        break\n",
    "    elif event == 'Preview Data':\n",
    "        preview_data()\n",
    "        \n",
    "    elif event == 'optimizer':\n",
    "        \n",
    "         window['optimizer_params'].update( values= list( optimizer_parameter_dict[ values['optimizer'] ] ) ) \n",
    "\n",
    "    elif event == 'optimizer_params':\n",
    "        \n",
    "        current_param_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']])\n",
    "        window['param_type'].update(current_param_type if current_param_type != int else float)\n",
    "        param_value = optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']]\n",
    "        window['param_value'].update( param_value if current_param_type != int else float(param_value) )\n",
    "       \n",
    "        \n",
    "    elif event == 'update':\n",
    "        current_param_type = type( optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] )\n",
    "        new_value = ''\n",
    "        if current_param_type == tuple:\n",
    "            indiv_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']][0])\n",
    "            if len(values['param_value'].split()) != 2:\n",
    "                print('incorrect input')\n",
    "            else:\n",
    "                new_value = ( indiv_type(values['param_value'].split()[0]) , indiv_type(values['param_value'].split()[1]) )\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "        else:\n",
    "            try:\n",
    "                new_value = current_param_type(values['param_value'])\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "            except:\n",
    "                print('incorrect input')\n",
    "                   \n",
    "    elif event == 'train_net':\n",
    "        net_plot.cla()\n",
    "        loss_plot.cla()\n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        window['train_bar'].UpdateBar(0)\n",
    "        window['val_bar'].UpdateBar(0)\n",
    "        window['epoch_bar'].UpdateBar(0)\n",
    "        t1 = threading.Thread(target=train_network , args = (draw_signal,stop_training) , daemon = True)\n",
    "        t1.start()\n",
    "        window['stop_training'].update(disabled = False)\n",
    "        \n",
    "    elif event =='stop_training':  \n",
    "        stop_training.put(1)\n",
    "        window['stop_training'].update(disabled = True)\n",
    "    elif event =='test':\n",
    "        draw_digit(model)\n",
    "    \n",
    "            \n",
    "    try:\n",
    "        draw_status = draw_signal.get_nowait()\n",
    "    except queue.Empty:\n",
    "        draw_status = None\n",
    "    \n",
    "    if draw_status:\n",
    "        \n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
