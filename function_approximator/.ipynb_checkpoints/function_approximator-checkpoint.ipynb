{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Beginner Template\n",
    "### pretty much all neural nets are a different flavor of this same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2f368cddf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data set class / retrieve data\n",
    "## usually we have to get our data then prepare it to be fed into the nural network\n",
    "### some of the things we usually do here are:\n",
    "* load the data either images or data points from some source ie (folder, download .etc) (usually done in the __init__ method)\n",
    "* turn our data into torch tensors as the network only works on tensors (usually done in the __getitem__ method this allows our object to behave like an indexable data structure)\n",
    "* can define other methods that help shape and shave our data , pre-processing, augmentations ..., etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, std_dev = 1 , order = 1 ):\n",
    "        \n",
    "        self.x = torch.randn(num_data_points,1)\n",
    "        self.y = 0\n",
    "        for i in range(1,order+1):\n",
    "            self.y += self.x**i \n",
    "        self.y += std_dev*torch.randn(num_data_points,1)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.x,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.plot(self.x.numpy(),self.y.numpy() , 'o')\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our Model \n",
    "* define our layer types and activation functions in the __init__ method \n",
    "* then implement the structure of our Neural Net in the __forward__ function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , num_layers = 1, width = 1):\n",
    "        super(my_model,self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,1)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "        pred = self.output_layer(x)\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our data\n",
    "* instantiate our dataset class \n",
    "* create a dataloader (its good practice to use a dataloader as it behaves as a generator object that will serve up one at a time (in batches) allows us to use memory efficiently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Dataset(num_data_points = 100, std_dev = 0.3 , order = 2)\n",
    "data_loader = DataLoader(data ,100)\n",
    "data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model \n",
    "* we have our data , we have our model , now we just run a simple for loop that will push the data through the model look at what pops out (line 16) and then goes back to correct what it thinks it did incorrectly(line 18) and we go again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(num_layers = 2, width = 4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters() , lr = 0.01)\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x,y in data_loader:\n",
    "        y_pred = model.forward(x)\n",
    "        loss = criterion(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss) \n",
    "    #     if i%100 == 0:\n",
    "    #         print(f'epoch:{i} loss:{loss.item()}')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            ax[0].cla()\n",
    "            ax[0].set_title(f'epoch:{i}')\n",
    "            ax[0].plot(x.numpy(),y.numpy(),'o')\n",
    "            ax[0].plot(x.numpy(),y_pred.data.numpy(),'go')\n",
    "            ax[1].cla()\n",
    "            ax[1].set_title(f'loss:{round(loss.item(),4)}')\n",
    "            ax[1].plot(np.array(losses)/len(losses) )\n",
    "            plt.pause(0.001)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
