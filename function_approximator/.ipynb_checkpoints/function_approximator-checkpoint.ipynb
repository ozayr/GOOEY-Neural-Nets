{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2f368cddf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, std_dev = 1 , order = 1 ):\n",
    "        \n",
    "        self.x = torch.randn(num_data_points,1)\n",
    "        self.y = 0\n",
    "        for i in range(1,order+1):\n",
    "            self.y += self.x**i \n",
    "        self.y += std_dev*torch.randn(num_data_points,1)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.x,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.plot(self.x.numpy(),self.y.numpy() , 'o')\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , num_layers = 1, width = 1):\n",
    "        super(my_model,self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,1)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "        pred = self.output_layer(x)\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Dataset(num_data_points = 100, std_dev = 0.3 , order = 2)\n",
    "data_loader = DataLoader(data ,100)\n",
    "data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(num_layers = 2, width = 4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters() , lr = 0.01)\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x,y in data_loader:\n",
    "        y_pred = model.forward(x)\n",
    "        loss = criterion(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss) \n",
    "    #     if i%100 == 0:\n",
    "    #         print(f'epoch:{i} loss:{loss.item()}')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            ax[0].cla()\n",
    "            ax[0].set_title(f'epoch:{i}')\n",
    "            ax[0].plot(x.numpy(),y.numpy(),'o')\n",
    "            ax[0].plot(x.numpy(),y_pred.data.numpy(),'go')\n",
    "            ax[1].cla()\n",
    "            ax[1].set_title(f'loss:{round(loss.item(),4)}')\n",
    "            ax[1].plot(np.array(losses)/len(losses) )\n",
    "            plt.pause(0.001)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PySimpleGUI as sg\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import numpy as np\n",
    "\n",
    "import inspect\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('dark_background')\n",
    "sg.theme('Black')\n",
    "\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, std_dev = 1 , order = 1 ):\n",
    "        \n",
    "        self.x = torch.randn(num_data_points,1)\n",
    "        self.y = 0\n",
    "        for i in range(1,order+1):\n",
    "            self.y += self.x**i \n",
    "        self.y += std_dev*torch.randn(num_data_points,1)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.x,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.plot(self.x.numpy(),self.y.numpy() , 'o')\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    \n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , num_layers = 1, width = 1):\n",
    "        super(my_model,self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,1)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "        pred = self.output_layer(x)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "\n",
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    return figure_canvas_agg\n",
    "\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if (v.default is not inspect.Parameter.empty) and (k != 'lr')\n",
    "    }\n",
    "\n",
    "\n",
    "x, y = '',''\n",
    "new_x,new_y = '',''\n",
    "epoch_num = ''\n",
    "\n",
    "def train_network(net_fig_queue,stop_training_queue):\n",
    "    \n",
    "    data_loader = DataLoader(data ,data_points)\n",
    "        \n",
    "    neurons = int(values['neuron_slider'] )\n",
    "    hidden_layers = int(values['hidden_slider'])\n",
    "    learning_rate = float(values['lr_slider']) \n",
    "    epochs = int(values['epoch_slider'])\n",
    "\n",
    "    model = my_model(num_layers = hidden_layers, width = neurons)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    parameter_tuple = tuple(optimizer_parameter_dict[values['optimizer']].values())\n",
    "    optimizer = getattr(torch.optim,values['optimizer'])(model.parameters(),learning_rate,*parameter_tuple)\n",
    "    \n",
    "\n",
    "    for i in range(epochs):\n",
    "        for x,y in data_loader:\n",
    "            y_pred = model.forward(x)\n",
    "            loss = criterion(y_pred,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item()) \n",
    " \n",
    "\n",
    "        try:\n",
    "            train_terminate = stop_training_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            train_terminate = None\n",
    "        finally:\n",
    "            if train_terminate:\n",
    "                break\n",
    "            elif i%int(values['plot_step']) == 0:\n",
    "                global new_x,new_y,epoch_num\n",
    "                epoch_num = i\n",
    "                new_x, new_y = zip(*sorted(zip(x.numpy(), y_pred.data.numpy())))\n",
    "                net_fig_queue.put(1)\n",
    "            \n",
    "\n",
    "    window['stop_training'].update(disabled = True)\n",
    "    \n",
    "\n",
    "\n",
    "text_len= len('GOOEY Neural Nets: Function Approximators')\n",
    "data_frame_text_len = len('Number of clusters:')\n",
    "model_frame_text_len = len('Number of neurons in layer:')\n",
    "optimizer_list = [optimizer for optimizer in  dir(torch.optim) if (optimizer not in ['Optimizer','lr_scheduler']) and ('__' not in optimizer  ) ]\n",
    "max_optim_len = max([len(string) for string in optimizer_list]) + 1\n",
    "optimizer_parameter_dict = {optimizer:get_default_args(getattr(torch.optim,optimizer)) for optimizer in optimizer_list }\n",
    "initial_optim_params_list = list( optimizer_parameter_dict[optimizer_list[0]] )\n",
    "init_params_dict = optimizer_parameter_dict[optimizer_list[0]]\n",
    "max_optim_len = max([len(string) for string in optimizer_list])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = [\n",
    "\n",
    "    [sg.Text('GOOEY Neural Nets: Function Approximators', size=(text_len, 1), justification='center', font=(\"Arial\", 25), relief=sg.RELIEF_RIDGE)],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Datapoints:',size = (data_frame_text_len,1)), sg.Slider(default_value = 1000,range=(0, 100000), size=(60, 20), orientation='h', key='data_slider')],\n",
    "        [sg.Text('noise in data:',size = (data_frame_text_len,1)), sg.Slider(default_value = 0.5,range=(0, 100) , resolution = 0.1, size=(60, 20), orientation='h', key='noise_slider')],\n",
    "        [sg.Text('function order:',size = (data_frame_text_len,1)) , sg.DropDown(values = list(range(1,11)) , default_value = 2, size = (5,1),key='func_order' ) ]\n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'DATA'  )   ],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Number of neurons in layer:',size = (model_frame_text_len,1) ),sg.Slider(default_value = 2, range=(1, 100), size=(60, 20), orientation='h', key='neuron_slider')     ],\n",
    "        [sg.Text('Number of hidden layers:',size = (model_frame_text_len,1)),sg.Slider(default_value = 2,range=(1, 100), size=(60, 20), orientation='h', key='hidden_slider')     ],\n",
    "        [sg.Text('Learning Rate:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 0.01,range=(0, 10),resolution=0.01, size=(60, 20), orientation='h', key='lr_slider')    ],\n",
    "        [sg.Text('Epochs:',size = (model_frame_text_len,1)),sg.Slider(default_value = 1000,range=(0, 10000),resolution=1, size=(60, 20), orientation='h', key='epoch_slider')     ],\n",
    "        [sg.Text('Optimizers:',size = (model_frame_text_len,1)),sg.DropDown(values = optimizer_list , default_value = optimizer_list[0],enable_events = True, key = 'optimizer',size = (max_optim_len,1))],\n",
    "        [sg.Text('Optimizer parameters:',size = (model_frame_text_len,1)), sg.DropDown(values = initial_optim_params_list, default_value = initial_optim_params_list[0], enable_events = True  , key ='optimizer_params')],\n",
    "        [sg.Text('parameter value:',size = (model_frame_text_len,1)),sg.Input( init_params_dict[ initial_optim_params_list[0]],tooltip = 'Enter in format shown', key = 'param_value',size = (10,1)) , sg.Text(type(init_params_dict[ initial_optim_params_list[0]]),key='param_type' ) , sg.Button('Update',key = 'update') ,sg.Button('reset all',key = 'reset')]\n",
    "        \n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'MODEL'  )   ],\n",
    "    \n",
    "    [sg.Button('Generate Data',key = 'gen_data'),sg.Button('Start Training',disabled=True,key = 'train_net'), sg.Text('Plot step size:') , sg.DropDown(values = list(range(0,1000,10)) ,default_value= 10,key = 'plot_step' ) ,sg.Button('Stop Training' , disabled = True, key = 'stop_training') ],\n",
    "    [sg.Canvas( size = (100,100) , key = 'net_canvas' ),sg.Canvas( size = (100,100) , key = 'loss_canvas' )],\n",
    "\n",
    "    \n",
    "    [sg.Button('Exit')]\n",
    "]      \n",
    "\n",
    "window = sg.Window('GOOEY Neural Nets', layout , finalize = True) \n",
    "\n",
    "# net canvas\n",
    "net_canvas_elem = window['net_canvas']\n",
    "net_canvas = net_canvas_elem.TKCanvas\n",
    "\n",
    "net_fig = plt.figure(figsize=(4,4))\n",
    "net_plot = net_fig.add_subplot(111)\n",
    "# net_plot.axis('off')\n",
    "net_fig_agg = draw_figure(net_canvas, net_fig)\n",
    "\n",
    "# loss canvas\n",
    "loss_canvas_elem = window['loss_canvas']\n",
    "loss_canvas = loss_canvas_elem.TKCanvas\n",
    "\n",
    "loss_fig = plt.figure(figsize=(4,4))\n",
    "loss_plot = loss_fig.add_subplot(111)\n",
    "# loss_plot.axis('off')\n",
    "loss_fig_agg = draw_figure(loss_canvas, loss_fig)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "draw_signal = queue.Queue()\n",
    "stop_training = queue.Queue()\n",
    "\n",
    "# =======\n",
    "model = ''\n",
    "criterion = ''\n",
    "optimizer = ''\n",
    "epochs = ''\n",
    "\n",
    "losses = []\n",
    "\n",
    "data_points = 0\n",
    "data = ''\n",
    "\n",
    "while 1:\n",
    "    event, values = window.read(timeout = 100)    \n",
    "    if event == 'Exit':\n",
    "        stop_training.put(1)\n",
    "        \n",
    "        try:\n",
    "            t1.join()\n",
    "        except:\n",
    "            pass\n",
    "        window.close()\n",
    "        break\n",
    "    elif event == 'optimizer':\n",
    "        \n",
    "         window['optimizer_params'].update( values= list( optimizer_parameter_dict[ values['optimizer'] ] ) ) \n",
    "\n",
    "    elif event == 'optimizer_params':\n",
    "        \n",
    "        current_param_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']])\n",
    "        window['param_type'].update(current_param_type if current_param_type != int else float)\n",
    "        param_value = optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']]\n",
    "        window['param_value'].update( param_value if current_param_type != int else float(param_value) )\n",
    "       \n",
    "        \n",
    "    elif event == 'update':\n",
    "        current_param_type = type( optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] )\n",
    "        new_value = ''\n",
    "        if current_param_type == tuple:\n",
    "            indiv_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']][0])\n",
    "            if len(values['param_value'].split()) != 2:\n",
    "                print('incorrect input')\n",
    "            else:\n",
    "                new_value = ( indiv_type(values['param_value'].split()[0]) , indiv_type(values['param_value'].split()[1]) )\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "        else:\n",
    "            try:\n",
    "                new_value = current_param_type(values['param_value'])\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "            except:\n",
    "                print('incorrect input')\n",
    "                \n",
    "    elif event == 'gen_data':\n",
    "        net_plot.cla()                   \n",
    "        new_x ,new_y = '',''\n",
    "#         net_plot.axis('off')\n",
    "        \n",
    "        data_points = int(values['data_slider']) # draw this many data points (on next line)\n",
    "        noise =  float(values['noise_slider'])\n",
    "        order = int(values['func_order'])\n",
    "        \n",
    "        data = Dataset(num_data_points = data_points, std_dev = noise , order = order)\n",
    "        \n",
    "        x,y = data.get_all_data()\n",
    "        \n",
    "        net_plot.scatter(x, y, color='yellow')\n",
    "        \n",
    "        net_fig_agg.draw()\n",
    "        window['train_net'].update(disabled = False)\n",
    "        \n",
    "    elif event == 'train_net':\n",
    "        losses = []\n",
    "        t1 = threading.Thread(target=train_network , args = (draw_signal,stop_training) , daemon = True)\n",
    "        t1.start()\n",
    "        window['stop_training'].update(disabled = False)\n",
    "    elif event =='stop_training':  \n",
    "        stop_training.put(1)\n",
    "        window['stop_training'].update(disabled = True)\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        draw_status = draw_signal.get_nowait()\n",
    "    except queue.Empty:\n",
    "        draw_status = None\n",
    "\n",
    "    if draw_status:\n",
    "\n",
    "        net_plot.cla()\n",
    "        net_plot.set_title(f'epoch:{epoch_num}')\n",
    "        net_plot.plot(x.numpy(),y.numpy(),'o', color = 'yellow')\n",
    "\n",
    "        net_plot.plot(new_x ,new_y,color = 'green',lw = '3')\n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "\n",
    "        loss_plot.cla()\n",
    "        loss_plot.set_yticklabels([])\n",
    "        loss_plot.set_title(f'loss:{round(losses[-1],4)}')\n",
    "        loss_plot.plot(np.array(losses))\n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
