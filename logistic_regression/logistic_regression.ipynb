{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb11c1d3a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "        \n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    " \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.Tensor(self.X[i])\n",
    "        if self.clusters > 2:\n",
    "            y_data =  torch.Tensor([1 if self.y[i] == j else 0 for j in range(self.clusters)]).long()\n",
    "        else:\n",
    "            y_data = torch.Tensor([self.y[i]])\n",
    "#         print(y_data,self.y[i])\n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "    \n",
    "        self.num_layers = num_layers\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "        pred = torch.sigmoid(self.output_layer(x))\n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        if pred.shape[1] > 2:\n",
    "            return np.argmax(pred.data.numpy(),axis=1)\n",
    "        else:\n",
    "            return [1 if p > 0.5 else 0 for p in pred ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(num_data_points = 100, num_clusters= 2, cluster_std=0.7 )\n",
    "data_loader = DataLoader(data ,100)\n",
    "data.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "output_size = data.clusters if data.clusters > 2 else 1\n",
    "\n",
    "model = my_model(input_size = 2 ,output_size = output_size, num_layers = 2, width = 4)\n",
    "\n",
    "if output_size  > 2:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.1)\n",
    "\n",
    "epochs = 2000\n",
    "losses = []\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x,y in data_loader:\n",
    "       \n",
    "        y_pred = model.forward(x)\n",
    "#         print( np.argmax(y,axis = 1), np.argmax(y_pred.data.numpy(), axis = 1) )\n",
    "        if output_size > 2:\n",
    "            loss = criterion( y_pred,  np.argmax(y,axis = 1) )\n",
    "        else:\n",
    "            loss = criterion( y_pred,y)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "        \n",
    "    if i%100 == 0:\n",
    "        print(f'epoch:{i} loss:{loss.item()}')\n",
    "#         y_pred = model.predict(x)\n",
    "            \n",
    "    if i%10 == 0:\n",
    "        X = x.numpy()\n",
    "        if output_size > 2:\n",
    "            y = np.argmax(y,axis=1).numpy()\n",
    "        else:\n",
    "            y = y.view(1,-1).numpy()[0]\n",
    "\n",
    "\n",
    "       \n",
    "        ax[0].cla()\n",
    "        ax[0].set_title(f'epoch:{i}')\n",
    "        h = 0.02\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "        Z = np.array(model.predict( torch.Tensor(np.c_[xx.ravel(), yy.ravel()])))\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        ax[0].imshow(Z, interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,\n",
    "        aspect='auto', origin='lower')\n",
    "\n",
    "        for i in range(data.clusters):\n",
    "            ax[0].scatter(X[y==i,0],X[y==i,1] )\n",
    "\n",
    "        ax[1].cla()\n",
    "        ax[1].set_title(f'loss:{round(loss.item(),4)}')\n",
    "        ax[1].plot(np.array(losses)/len(losses) )\n",
    "        plt.pause(0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD8CAYAAACCaZo+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQIUlEQVR4nO3aW2hUZ9uH8X8S561Sd9RYhJmpCZjohBxENIknYootIUKag1aqWGrbEJsWLUgpAT2oQSjU0opQKTIIdmNJ01JqwIitqEXByIJstNGkM3bEmQbFTfWkilGe9+DFfB0Ss26zm6Tf9YPnYGWerNyGmcvJmpUlyQkADLIzPQCAqYNgADAjGADMCAYAM4IBwIxgADDzDcb+/ft17do1nT9//rF79uzZo1gspq6uLi1dunRMBwQwubjh1sqVK93SpUvd+fPnh3y8qqrKtba2OkmuvLzctbW1DXs+Fos1dZfvO4xTp07p1q1bj328pqZGX331lSTp7Nmzmjt3rhYsWOB3WgBT0LTRniAYDCqZTA4cp1IpBYNBXb16ddDeuro6bdq0SZK0ePFi9fb2jvbHA3hCCxcu1LPPPjui7x11MLKysgZ9zTk35N5oNKpoNCpJ8jxPpaWlo/3xAJ6Q53kj/t5Rf0qSSqUUDocHjkOhkPr6+kZ7WgCT0KiD0dLSotdff12SVF5erjt37gz55wiAqc/3T5Jvv/1WFRUVys3NVTKZ1IcffqhAICBJ2rdvn1pbW7VmzRrF43H9/fffevPNN8d9aACZk5GPZzzPy/hHRCzW/8c1mtced3oCMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzggHAjGAAMCMYAMwIBgAzUzAqKyvV09OjWCymhoaGQY+Hw2EdP35c7e3t6urqUlVV1ZgPCmBycMOt7OxsF4/HXX5+vgsEAq6zs9NFIpG0Pfv27XP19fVOkotEIi6RSAx7TknO8zzfPSwWa+zXaF57vu8wysrKFI/HlUgk1N/fr6amJtXU1KTtcc5p9uzZkqQ5c+aor6/P77QApqBpfhuCwaCSyeTAcSqVUnl5edqeHTt26Oeff9aWLVv09NNP64UXXhjyXHV1ddq0aZMkKTc3dzRzA8gA33cYWVlZg77mnEs7Xr9+vQ4cOKBwOKw1a9bo66+/HvL7otGoSktLVVpaqhs3boxibACZ4BuMVCqlcDg8cBwKhQb9yVFbW6vm5mZJUltbm6ZPn847COBfyDcYnuepoKBAeXl5CgQCWrdunVpaWtL2XLlyRatXr5YkLVmyRNOnT9f169fHZ2IAGeV7ZbSqqsr19va6eDzutm3b5iS5xsZGV11d7aT/fTJy+vRp19nZ6To6OtyLL744rldqWSzWyNcoX3tTcmgWizXCNa4fqwLAIwQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgBnBAGBGMACYEQwAZgQDgJkpGJWVlerp6VEsFlNDQ8OQe9auXavu7m799ttvOnjw4JgOCWDycMOt7OxsF4/HXX5+vgsEAq6zs9NFIpG0PYsWLXLt7e1u7ty5TpKbP3/+sOeU5DzP893DYrHGfo3mtef7DqOsrEzxeFyJREL9/f1qampSTU1N2p66ujrt3btXt2/fliRdv37d77QApiDfYASDQSWTyYHjVCqlYDCYtqewsFCFhYU6ffq0zpw5o8rKyiHPVVdXJ8/z5HmecnNzRzk6gIk2zW9DVlbWoK8559JPMm2aCgoKVFFRoVAopFOnTqm4uFh37txJ2xeNRhWNRiVJnueNZm4AGeD7DiOVSikcDg8ch0Ih9fX1Ddpz6NAhPXjwQJcvX1Zvb68KCgrGfloAGeUbDM/zVFBQoLy8PAUCAa1bt04tLS1pe3766Sc9//zzkqR58+apsLBQf/zxx/hMDCBjfIPx8OFDbd68WUePHtXFixfV3NysCxcuqLGxUdXV1ZKko0eP6ubNm+ru7taJEyf0wQcf6NatW+M+PICJN+U+2mGxWCNf4/qxKgA8QjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGYEA4AZwQBgRjAAmBEMAGamYFRWVqqnp0exWEwNDQ2P3ffyyy/LOadly5aN2YAAJg/fYGRnZ2vv3r2qqqpSUVGR1q9fr0gkMmjfzJkz9d5776mtrW1cBgWQeb7BKCsrUzweVyKRUH9/v5qamlRTUzNo386dO7Vr1y7du3dvXAYFkHm+wQgGg0omkwPHqVRKwWAwbU9JSYnC4bAOHz487Lnq6urkeZ48z1Nubu4IRwaQKb7ByMrKGvQ151za47t379b777/v+8Oi0ahKS0tVWlqqGzduPOGoADLNNxipVErhcHjgOBQKqa+vb+B41qxZKi4u1smTJ5VIJLRixQq1tLRw4RP4l3LDrZycHHfp0iWXl5fnAoGA6+zsdEVFRY/df+LECbds2bJhzynJeZ7nu4fFYo39Gs1rz/cdxsOHD7V582YdPXpUFy9eVHNzsy5cuKDGxkZVV1f7fTuAf5kpVzkWizXyNa7vMADgEYIBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwMwUjMrKSvX09CgWi6mhoWHQ41u3blV3d7e6urp07NgxPffcc2M+KIDJwQ23srOzXTwed/n5+S4QCLjOzk4XiUTS9lRUVLgZM2Y4Sa6+vt41NTUNe05JzvM83z0sFmvs12hee77vMMrKyhSPx5VIJNTf36+mpibV1NSk7Tl58qTu3r0rSWpra1MoFPI7LYApyDcYwWBQyWRy4DiVSikYDD52f21trY4cOTLkY3V1dfI8T57nKTc3dwTjAsikaX4bsrKyBn3NOTfk3g0bNmj58uVatWrVkI9Ho1FFo1FJkud5TzIngEnANxipVErhcHjgOBQKqa+vb9C+1atXa/v27Vq1apXu378/tlMCmDSGvciRk5PjLl265PLy8gYuehYVFaXtKSkpcfF43C1atGhCLrywWKyRr3G96Pnw4UNt3rxZR48e1cWLF9Xc3KwLFy6osbFR1dXVkqRPPvlEM2fO1Pfff6+Ojg4dOnTI77QApqgpVzkWizXyNa7vMADgEYIBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAjGADMCAYAM4IBwIxgADAzBaOyslI9PT2KxWJqaGgY9Ph//vMfNTU1KRaLqa2tTQsXLhzzQQFknm8wsrOztXfvXlVVVamoqEjr169XJBJJ21NbW6u//vpLBQUF2r17tz7++ONxGxhA5vgGo6ysTPF4XIlEQv39/WpqalJNTU3anpqaGn355ZeSpB9++EGrV68en2kBZNQ0vw3BYFDJZHLgOJVKqby8/LF7Hj58qDt37mjevHm6efNm2r66ujpt2rRJklRcXCzP80b9D5hIubm5unHjRqbHMJtq80rMPBEWL1484u/1DUZWVtagrznnnniPJEWjUUWjUUmS53kqLS01DzoZTLWZp9q8EjNPhNH8R+37J0kqlVI4HB44DoVC6uvre+yenJwczZkzR7du3RrxUAAmJ99geJ6ngoIC5eXlKRAIaN26dWppaUnb09LSoo0bN0qSXnnlFR0/fnx8pgWQUTmSdgy3wTmnWCymgwcPasuWLfrmm2/0448/qrGxUbNmzdLvv/+uc+fOacOGDfroo49UUlKi+vp63b592/eHt7e3j9E/Y+JMtZmn2rwSM0+Ekc6bJWnwxQYAGAJ3egIwIxgAzMY9GFPttnK/ebdu3aru7m51dXXp2LFjeu655zIwZTq/mR95+eWX5ZzTsmXLJnC6oVlmXrt2rbq7u/Xbb7/p4MGDEzxhOr95w+Gwjh8/rvb2dnV1damqqioDU/6f/fv369q1azp//vxj9+zZs0exWExdXV1aunSp+dxuvFZ2draLx+MuPz/fBQIB19nZ6SKRSNqed955x33xxRdOknv11VddU1PTuM0zFvNWVFS4GTNmOEmuvr4+o/NaZ5bkZs6c6X799Vd35swZt2zZskk/86JFi1x7e7ubO3euk+Tmz58/qefdt2+fq6+vd5JcJBJxiUQio7/jlStXuqVLl7rz588P+XhVVZVrbW11klx5eblra2uz/S40jqbabeWWeU+ePKm7d+9Kktra2hQKhTIx6gDLzJK0c+dO7dq1S/fu3cvAlOksM9fV1Wnv3r0Dn7Zdv349E6NKss3rnNPs2bMlSXPmzBl0r9JEO3Xq1LD3QtXU1Oirr76SJJ09e1Zz587VggULfM87rsEY6rbyYDD42D3/vK08Eyzz/lNtba2OHDkyEaM9lmXmkpIShcNhHT58eKLHG5Jl5sLCQhUWFur06dM6c+aMKisrJ3rMAZZ5d+zYoddee03JZFKtra3asmXLRI/5RJ70uf6I763hozGWt5VPhCeZZcOGDVq+fLlWrVo13mMNy2/mrKws7d69W2+88cYETjU8y+952rRpKigoUEVFhUKhkE6dOqXi4mLduXNnosYcYJl3/fr1OnDggD777DOtWLFCX3/9tYqLizP2XPYz0tfduL7DmGq3lVvmlaTVq1dr+/bteumll3T//v2JHHEQv5lnzZql4uJinTx5UolEQitWrFBLS0tGL3xanxeHDh3SgwcPdPnyZfX29qqgoGCiRx2YxW/e2tpaNTc3S/rfn6rTp09Xbm7uhM75JKzP9aGM24WXnJwcd+nSJZeXlzdwsaioqChtz7vvvpt20fO7777L2IUiy7wlJSUuHo+7RYsWZfSi1pPM/M914sSJjF/0tMxcWVnpDhw44CS5efPmuStXrrhnnnlm0s7b2trqNm7c6CS5JUuWuD///DPjz42FCxc+9qLnmjVr0i56nj171nre8R26qqrK9fb2ung87rZt2+YkucbGRlddXe0kuaeeeso1Nze7WCzmzp496/Lz8zP6S/ab95dffnFXr151HR0drqOjwx06dCjjTwy/mf+5JkMwrDN/+umnrru72507d869+uqrk3reSCTiTp8+7To7O11HR4d78cUXMzrvt99+6/r6+tz9+/ddMpl0b731lnv77bfd22+/PbDn888/d/F43J07d878nODWcABm3OkJwIxgADAjGADMCAYAM4IBwIxgADAjGADM/gupATLQWFsdjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "import inspect\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('dark_background')\n",
    "sg.theme('Black')\n",
    "\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "        \n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    " \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.Tensor(self.X[i])\n",
    "        if self.clusters > 2:\n",
    "            y_data =  torch.Tensor([1 if self.y[i] == j else 0 for j in range(self.clusters)]).long()\n",
    "        else:\n",
    "            y_data = torch.Tensor([self.y[i]])\n",
    "#         print(y_data,self.y[i])\n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "        pred = torch.sigmoid(self.output_layer(x))\n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        if pred.shape[1] > 2:\n",
    "            return np.argmax(pred.data.numpy(),axis=1)\n",
    "        else:\n",
    "            return [1 if p > 0.5 else 0 for p in pred ]\n",
    "    \n",
    "\n",
    "\n",
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    return figure_canvas_agg\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if (v.default is not inspect.Parameter.empty) and (k != 'lr')\n",
    "    }\n",
    "\n",
    "xx,yy = '',''\n",
    "Z = ''\n",
    "def train_network(net_fig_queue,stop_training_queue ):\n",
    "    global model\n",
    "    data_loader = DataLoader(data ,data_points)\n",
    "\n",
    "    neurons = int(values['neuron_slider'] )\n",
    "    hidden_layers = int(values['hidden_slider'])\n",
    "    learning_rate = float(values['lr_slider']) \n",
    "    epochs = int(values['epoch_slider'])\n",
    "\n",
    "    output_size = data.clusters if data.clusters > 2 else 1\n",
    "\n",
    "    model = my_model(input_size = 2 ,output_size = output_size, num_layers = hidden_layers, width = neurons)\n",
    "\n",
    "    if output_size  > 2:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    parameter_tuple = tuple(optimizer_parameter_dict[values['optimizer']].values())\n",
    "    optimizer = getattr(torch.optim,values['optimizer'])(model.parameters(),learning_rate,*parameter_tuple)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for x,y in data_loader:\n",
    "\n",
    "            y_pred = model.forward(x)\n",
    "    #         print( np.argmax(y,axis = 1), np.argmax(y_pred.data.numpy(), axis = 1) )\n",
    "            if output_size > 2:\n",
    "                loss = criterion( y_pred,  np.argmax(y,axis = 1) )\n",
    "            else:\n",
    "                loss = criterion( y_pred,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        #if i%100 == 0:\n",
    "            #print(f'epoch:{i} loss:{loss.item()}')\n",
    "    #         y_pred = model.predict(x)\n",
    "        try:\n",
    "            train_terminate = stop_training_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            train_terminate = None\n",
    "        finally:\n",
    "            if train_terminate:\n",
    "                break\n",
    "\n",
    "            elif i%int(values['plot_step']) == 0:\n",
    "                \n",
    "                epoch_num = i \n",
    "                X = x.numpy()\n",
    "                if output_size > 2:\n",
    "                    y = np.argmax(y,axis=1).numpy()\n",
    "                else:\n",
    "                    y = y.view(1,-1).numpy()[0]\n",
    "\n",
    "                net_plot.cla()\n",
    "                net_plot.set_title(f'epoch:{i}')\n",
    "                h = 0.02\n",
    "                x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "                y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "                global xx,yy,Z\n",
    "                xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "                Z = np.array(model.predict( torch.Tensor(np.c_[xx.ravel(), yy.ravel()])))\n",
    "                # Put the result into a color plot\n",
    "                Z = Z.reshape(xx.shape)\n",
    "\n",
    "                \n",
    "            \n",
    "                colors = cm.seismic(np.linspace(0, 1, data.clusters))\n",
    "                for i,c in zip(range(data.clusters),colors):\n",
    "                    net_plot.scatter(X[y==i,0],X[y==i,1],color = c )\n",
    "\n",
    "\n",
    "                loss_plot.cla()\n",
    "            #             loss_plot.draw_artist(loss_plot.patch)\n",
    "                loss_plot.set_title(f'loss:{round(losses[-1],4)}')\n",
    "                loss_plot.set_yticklabels([])\n",
    "                loss_plot.plot(np.array(losses) )\n",
    "                        \n",
    "    \n",
    "                net_fig_queue.put(1)\n",
    "    \n",
    "        \n",
    "\n",
    "    window['stop_training'].update(disabled = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_len= len('GOOEY Neural Nets: Function Approximators')\n",
    "data_frame_text_len = len('Number of clusters:')\n",
    "model_frame_text_len = len('Number of neurons in layer:')\n",
    "optimizer_list = [optimizer for optimizer in  dir(torch.optim) if (optimizer not in ['Optimizer','lr_scheduler']) and ('__' not in optimizer  ) ]\n",
    "max_optim_len = max([len(string) for string in optimizer_list]) + 1\n",
    "optimizer_parameter_dict = {optimizer:get_default_args(getattr(torch.optim,optimizer)) for optimizer in optimizer_list }\n",
    "initial_optim_params_list = list( optimizer_parameter_dict[optimizer_list[0]] )\n",
    "init_params_dict = optimizer_parameter_dict[optimizer_list[0]]\n",
    "max_optim_len = max([len(string) for string in optimizer_list])\n",
    "\n",
    "\n",
    "layout = [\n",
    "\n",
    "    [sg.Text('GOOEY Neural Nets: Logistic Regression', size=(text_len, 1), justification='center', font=(\"Defau\", 25), relief=sg.RELIEF_RIDGE)],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Datapoints:',size = (data_frame_text_len,1)), sg.Slider(default_value = 1000,range=(0, 100000), size=(60, 20), orientation='h', key='data_slider')],\n",
    "        [sg.Text('noise in data:',size = (data_frame_text_len,1)), sg.Slider(default_value = 0.5,range=(0, 100) , resolution = 0.1, size=(60, 20), orientation='h', key='noise_slider')],\n",
    "        [sg.Text('Number of clusters:',size = (data_frame_text_len,1)) , sg.DropDown(values = list(range(1,11)) , default_value = 2, size = (5,1),key='cluster_slider' ) ]\n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'DATA'  )   ],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Number of neurons in layer:',size = (model_frame_text_len,1) ),sg.Slider(default_value = 2, range=(1, 100), size=(60, 20), orientation='h', key='neuron_slider')     ],\n",
    "        [sg.Text('Number of hidden layers:',size = (model_frame_text_len,1)),sg.Slider(default_value = 2,range=(1, 100), size=(60, 20), orientation='h', key='hidden_slider')     ],\n",
    "        [sg.Text('Learning Rate:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 0.01,range=(0, 10),resolution=0.01, size=(60, 20), orientation='h', key='lr_slider')    ],\n",
    "        [sg.Text('Epochs:',size = (model_frame_text_len,1)),sg.Slider(default_value = 1000,range=(0, 10000),resolution=1, size=(60, 20), orientation='h', key='epoch_slider')     ],\n",
    "        [sg.Text('Optimizers:',size = (model_frame_text_len,1)),sg.DropDown(values = optimizer_list , default_value = optimizer_list[0],enable_events = True, key = 'optimizer',size = (max_optim_len,1))],\n",
    "        [sg.Text('Optimizer parameters:',size = (model_frame_text_len,1)), sg.DropDown(values = initial_optim_params_list, default_value = initial_optim_params_list[0], enable_events = True  , key ='optimizer_params')],\n",
    "        [sg.Text('parameter value:',size = (model_frame_text_len,1)),sg.Input( init_params_dict[ initial_optim_params_list[0]],tooltip = 'Enter in format shown', key = 'param_value',size = (10,1)) , sg.Text(type(init_params_dict[ initial_optim_params_list[0]]),key='param_type' ) , sg.Button('Update',key = 'update') ,sg.Button('reset all',key = 'reset')]\n",
    "        \n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'MODEL'  )   ],\n",
    "    \n",
    "    [sg.Button('Generate Data',key = 'gen_data'),sg.Button('Start Training',disabled=True,key = 'train_net'), sg.Text('Plot step size:') , sg.DropDown(values = list(range(0,1000,10)) ,default_value= 10,key = 'plot_step' ) ,sg.Button('Stop Training' , disabled = True, key = 'stop_training') ],\n",
    "    [sg.Canvas( size = (100,100) , key = 'net_canvas' ),sg.Canvas( size = (100,100) , key = 'loss_canvas' )],\n",
    "    \n",
    "    \n",
    "    [sg.Button('Exit')]\n",
    "]      \n",
    "\n",
    "window = sg.Window('GOOEY Neural Nets', layout , finalize = True) \n",
    "\n",
    "# net canvas\n",
    "net_canvas_elem = window['net_canvas']\n",
    "net_canvas = net_canvas_elem.TKCanvas\n",
    "\n",
    "net_fig = plt.figure(figsize=(4,4))\n",
    "net_plot = net_fig.add_subplot(111)\n",
    "# net_plot.grid()\n",
    "net_fig_agg = draw_figure(net_canvas, net_fig)\n",
    "\n",
    "# loss canvas\n",
    "loss_canvas_elem = window['loss_canvas']\n",
    "loss_canvas = loss_canvas_elem.TKCanvas\n",
    "\n",
    "loss_fig = plt.figure(figsize=(4,4))\n",
    "loss_plot = loss_fig.add_subplot(111)\n",
    "# loss_plot.grid()\n",
    "loss_fig_agg = draw_figure(loss_canvas, loss_fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "draw_signal = queue.Queue()\n",
    "stop_training = queue.Queue()\n",
    "\n",
    "# =======\n",
    "model = ''\n",
    "criterion = ''\n",
    "optimizer = ''\n",
    "epochs = ''\n",
    "\n",
    "losses = []\n",
    "\n",
    "data_points = 0\n",
    "data = ''\n",
    "#===========\n",
    "while 1:\n",
    "    event, values = window.read(timeout = 100)    \n",
    "    if event == 'Exit':\n",
    "        stop_training.put(1)\n",
    "        window.close()\n",
    "        break\n",
    "    elif event == 'optimizer':\n",
    "        \n",
    "         window['optimizer_params'].update( values= list( optimizer_parameter_dict[ values['optimizer'] ] ) ) \n",
    "\n",
    "    elif event == 'optimizer_params':\n",
    "        \n",
    "        current_param_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']])\n",
    "        window['param_type'].update(current_param_type if current_param_type != int else float)\n",
    "        param_value = optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']]\n",
    "        window['param_value'].update( param_value if current_param_type != int else float(param_value) )\n",
    "       \n",
    "        \n",
    "    elif event == 'update':\n",
    "        current_param_type = type( optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] )\n",
    "        new_value = ''\n",
    "        if current_param_type == tuple:\n",
    "            indiv_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']][0])\n",
    "            if len(values['param_value'].split()) != 2:\n",
    "                print('incorrect input')\n",
    "            else:\n",
    "                new_value = ( indiv_type(values['param_value'].split()[0]) , indiv_type(values['param_value'].split()[1]) )\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "        else:\n",
    "            try:\n",
    "                new_value = current_param_type(values['param_value'])\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "            except:\n",
    "                print('incorrect input')\n",
    "                \n",
    "#         \n",
    "        \n",
    "    elif event == 'gen_data':\n",
    "        \n",
    "        net_plot.cla()                    # clear the subplot\n",
    "#         net_plot.grid()                   # draw the grid\n",
    "        \n",
    "        data_points = int(values['data_slider']) # draw this many data points (on next line)\n",
    "        noise =  float(values['noise_slider'])\n",
    "        num_clusters = int(values['cluster_slider'])\n",
    "        \n",
    "        data = Dataset(num_data_points = data_points, num_clusters = num_clusters , cluster_std = noise)\n",
    "        X,y = data.get_all_data()\n",
    "        \n",
    "        colors = cm.seismic(np.linspace(0, 1, data.clusters))\n",
    "        for i,c in zip(range(data.clusters),colors):\n",
    "            net_plot.scatter(X[y==i,0],X[y==i,1],color = c )\n",
    "        \n",
    "        net_fig_agg.draw()\n",
    "        window['train_net'].update(disabled = False)\n",
    "        \n",
    "        \n",
    "    elif event == 'train_net':\n",
    "        losses = []\n",
    "        t1 = threading.Thread(target=train_network , args = (draw_signal,stop_training) , daemon = True)\n",
    "        t1.start()\n",
    "        window['stop_training'].update(disabled = False)\n",
    "    elif event =='stop_training':  \n",
    "        stop_training.put(1)\n",
    "        window['stop_training'].update(disabled = True)\n",
    "        \n",
    "            \n",
    "    try:\n",
    "        draw_status = draw_signal.get_nowait()\n",
    "    except queue.Empty:\n",
    "        draw_status = None\n",
    "    \n",
    "    if draw_status:\n",
    "        \n",
    "        net_plot.imshow(Z, interpolation='nearest',\n",
    "                extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                cmap = plt.cm.Dark2,\n",
    "                aspect='auto', origin='lower')\n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
