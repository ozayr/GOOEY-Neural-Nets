{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "some notes , torch.Tensor returns a float Tensor where as torch.tensor infers the type , \n",
    "the forward function requires the data as float tensors\n",
    "when using CrossEntropyLoss the loss function requires the target values as long tensors\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "        \n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    " \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.tensor(self.X[i]).float()\n",
    "        y_data = torch.tensor(self.y[i])\n",
    "        \n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.binary = True if self.output_size < 3 else False\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "            \n",
    "        pred = torch.sigmoid(self.output_layer(x)) if self.binary else self.output_layer(x)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        if pred.shape[1] > 2:\n",
    "            return np.argmax(pred.data.numpy(),axis=1)\n",
    "        else:\n",
    "            return np.round(pred.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(num_data_points = 100, num_clusters= 2, cluster_std=0.7 )\n",
    "data_loader = DataLoader(data ,100)\n",
    "# data.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "output_size = data.clusters if data.clusters > 2 else 1\n",
    "\n",
    "model = my_model(input_size = 2 ,output_size = output_size, num_layers = 2, width = 4)\n",
    "\n",
    "if output_size  > 2:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.1)\n",
    "\n",
    "epochs = 2000\n",
    "losses = []\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(epochs):\n",
    "  \n",
    "    for x,y in data_loader:\n",
    "       \n",
    "        y_pred = model.forward(x)\n",
    "\n",
    "        if output_size > 2:\n",
    "            loss = criterion( y_pred, y )\n",
    "        else:\n",
    "            loss = criterion( y_pred.view(-1),y.float())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(f'epoch:{i} loss:{loss.item()}')\n",
    "#         y_pred = model.predict(x)\n",
    "            \n",
    "    if i%10 == 0:\n",
    "                \n",
    "        X = x.numpy()\n",
    "        y = y.numpy()\n",
    "       \n",
    "        ax[0].cla()\n",
    "        ax[0].set_title(f'epoch:{i}')\n",
    "        h = 0.02\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "       \n",
    "        Z = np.array(model.predict(torch.Tensor(np.c_[xx.ravel(), yy.ravel()])))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        ax[0].imshow(Z, interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,\n",
    "        aspect='auto', origin='lower')\n",
    "\n",
    "        for i in range(data.clusters):\n",
    "            ax[0].scatter(X[y==i,0],X[y==i,1] )\n",
    "       \n",
    "        ax[1].cla()\n",
    "        ax[1].set_title(f'loss:{round(loss.item(),4)}')\n",
    "        ax[1].plot(np.array(losses)/len(losses) )\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "import inspect\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('dark_background')\n",
    "sg.theme('Black')\n",
    "\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "        \n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    " \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.tensor(self.X[i]).float()\n",
    "        y_data = torch.tensor(self.y[i])\n",
    "        \n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.binary = True if self.output_size < 3 else False\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "            \n",
    "        pred = torch.sigmoid(self.output_layer(x)) if self.binary else self.output_layer(x)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        if pred.shape[1] > 2:\n",
    "            return np.argmax(pred.data.numpy(),axis=1)\n",
    "        else:\n",
    "            return np.round(pred.detach().numpy())\n",
    "    \n",
    "\n",
    "\n",
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    return figure_canvas_agg\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if (v.default is not inspect.Parameter.empty) and (k != 'lr')\n",
    "    }\n",
    "\n",
    "xx,yy = '',''\n",
    "Z = ''\n",
    "def train_network(net_fig_queue,stop_training_queue ):\n",
    "    global model\n",
    "    data_loader = DataLoader(data ,data_points)\n",
    "\n",
    "    neurons = int(values['neuron_slider'] )\n",
    "    hidden_layers = int(values['hidden_slider'])\n",
    "    learning_rate = float(values['lr_slider']) \n",
    "    epochs = int(values['epoch_slider'])\n",
    "\n",
    "    output_size = data.clusters if data.clusters > 2 else 1\n",
    "\n",
    "    model = my_model(input_size = 2 ,output_size = output_size, num_layers = hidden_layers, width = neurons)\n",
    "\n",
    "    if output_size  > 2:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    parameter_tuple = tuple(optimizer_parameter_dict[values['optimizer']].values())\n",
    "    optimizer = getattr(torch.optim,values['optimizer'])(model.parameters(),learning_rate,*parameter_tuple)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for x,y in data_loader:\n",
    "\n",
    "            y_pred = model.forward(x)\n",
    "    #         print( np.argmax(y,axis = 1), np.argmax(y_pred.data.numpy(), axis = 1) )\n",
    "            if output_size > 2:\n",
    "                loss = criterion( y_pred, y )\n",
    "            else:\n",
    "                loss = criterion( y_pred.view(-1),y.float())\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        #if i%100 == 0:\n",
    "            #print(f'epoch:{i} loss:{loss.item()}')\n",
    "    #         y_pred = model.predict(x)\n",
    "        try:\n",
    "            train_terminate = stop_training_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            train_terminate = None\n",
    "        finally:\n",
    "            if train_terminate:\n",
    "                break\n",
    "\n",
    "            elif i%int(values['plot_step']) == 0:\n",
    "                \n",
    "                epoch_num = i \n",
    "                X = x.numpy()\n",
    "                y = y.numpy()\n",
    "\n",
    "                net_plot.cla()\n",
    "                net_plot.set_title(f'epoch:{i}')\n",
    "                h = 0.02\n",
    "                x_span = np.linspace( min(X[:, 0]), max(X[:, 0]))\n",
    "                y_span = np.linspace( min(X[:, 1]), max(X[:, 1]))\n",
    "                global xx,yy,Z\n",
    "                xx, yy = np.meshgrid(x_span, y_span)\n",
    "\n",
    "\n",
    "                Z = np.array(model.predict( torch.Tensor(np.c_[xx.ravel(), yy.ravel()]))).reshape(xx.shape)\n",
    "                net_plot.contourf(xx,yy,Z )\n",
    "                \n",
    "\n",
    "                colors = cm.seismic(np.linspace(0, 1, data.clusters))\n",
    "                for i,c in zip(range(data.clusters),colors):\n",
    "                    net_plot.scatter(X[y==i,0],X[y==i,1],color = c )\n",
    "\n",
    "\n",
    "                loss_plot.cla()\n",
    "            #             loss_plot.draw_artist(loss_plot.patch)\n",
    "                loss_plot.set_title(f'loss:{round(losses[-1],4)}')\n",
    "                loss_plot.set_yticklabels([])\n",
    "                loss_plot.plot(np.array(losses) )\n",
    "                        \n",
    "    \n",
    "                net_fig_queue.put(1)\n",
    "    \n",
    "        \n",
    "\n",
    "    window['stop_training'].update(disabled = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_len= len('GOOEY Neural Nets: Function Approximators')\n",
    "data_frame_text_len = len('Number of clusters:')\n",
    "model_frame_text_len = len('Number of neurons in layer:')\n",
    "optimizer_list = [optimizer for optimizer in  dir(torch.optim) if (optimizer not in ['Optimizer','lr_scheduler']) and ('__' not in optimizer  ) ]\n",
    "max_optim_len = max([len(string) for string in optimizer_list]) + 1\n",
    "optimizer_parameter_dict = {optimizer:get_default_args(getattr(torch.optim,optimizer)) for optimizer in optimizer_list }\n",
    "initial_optim_params_list = list( optimizer_parameter_dict[optimizer_list[0]] )\n",
    "init_params_dict = optimizer_parameter_dict[optimizer_list[0]]\n",
    "max_optim_len = max([len(string) for string in optimizer_list])\n",
    "\n",
    "\n",
    "layout = [\n",
    "\n",
    "    [sg.Text('GOOEY Neural Nets: Logistic Regression', size=(text_len, 1), justification='center', font=(\"Defau\", 25), relief=sg.RELIEF_RIDGE)],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Datapoints:',size = (data_frame_text_len,1)), sg.Slider(default_value = 1000,range=(0, 100000), size=(60, 20), orientation='h', key='data_slider')],\n",
    "        [sg.Text('noise in data:',size = (data_frame_text_len,1)), sg.Slider(default_value = 0.5,range=(0, 100) , resolution = 0.1, size=(60, 20), orientation='h', key='noise_slider')],\n",
    "        [sg.Text('Number of clusters:',size = (data_frame_text_len,1)) , sg.DropDown(values = list(range(1,11)) , default_value = 2, size = (5,1),key='cluster_slider' ) ]\n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'DATA'  )   ],\n",
    "    \n",
    "    [sg.Frame(layout = [\n",
    "    \n",
    "        [sg.Text('Number of neurons in layer:',size = (model_frame_text_len,1) ),sg.Slider(default_value = 2, range=(1, 100), size=(60, 20), orientation='h', key='neuron_slider')     ],\n",
    "        [sg.Text('Number of hidden layers:',size = (model_frame_text_len,1)),sg.Slider(default_value = 2,range=(1, 100), size=(60, 20), orientation='h', key='hidden_slider')     ],\n",
    "        [sg.Text('Learning Rate:',size = (model_frame_text_len,1)) ,sg.Slider(default_value = 0.01,range=(0, 10),resolution=0.01, size=(60, 20), orientation='h', key='lr_slider')    ],\n",
    "        [sg.Text('Epochs:',size = (model_frame_text_len,1)),sg.Slider(default_value = 1000,range=(0, 10000),resolution=1, size=(60, 20), orientation='h', key='epoch_slider')     ],\n",
    "        [sg.Text('Optimizers:',size = (model_frame_text_len,1)),sg.DropDown(values = optimizer_list , default_value = optimizer_list[0],enable_events = True, key = 'optimizer',size = (max_optim_len,1))],\n",
    "        [sg.Text('Optimizer parameters:',size = (model_frame_text_len,1)), sg.DropDown(values = initial_optim_params_list, default_value = initial_optim_params_list[0], enable_events = True  , key ='optimizer_params')],\n",
    "        [sg.Text('parameter value:',size = (model_frame_text_len,1)),sg.Input( init_params_dict[ initial_optim_params_list[0]],tooltip = 'Enter in format shown', key = 'param_value',size = (10,1)) , sg.Text(type(init_params_dict[ initial_optim_params_list[0]]),key='param_type' ) , sg.Button('Update',key = 'update') ,sg.Button('reset all',key = 'reset')]\n",
    "        \n",
    "        \n",
    "    \n",
    "    ], relief = sg.RELIEF_SUNKEN , title = 'MODEL'  )   ],\n",
    "    \n",
    "    [sg.Button('Generate Data',key = 'gen_data'),sg.Button('Start Training',disabled=True,key = 'train_net'), sg.Text('Plot step size:') , sg.DropDown(values = list(range(0,1000,10)) ,default_value= 10,key = 'plot_step' ) ,sg.Button('Stop Training' , disabled = True, key = 'stop_training') ],\n",
    "    [sg.Canvas( size = (100,100) , key = 'net_canvas' ),sg.Canvas( size = (100,100) , key = 'loss_canvas' )],\n",
    "    \n",
    "    \n",
    "    [sg.Button('Exit')]\n",
    "]      \n",
    "\n",
    "window = sg.Window('GOOEY Neural Nets', layout , finalize = True) \n",
    "\n",
    "# net canvas\n",
    "net_canvas_elem = window['net_canvas']\n",
    "net_canvas = net_canvas_elem.TKCanvas\n",
    "\n",
    "net_fig = plt.figure(figsize=(4,4))\n",
    "net_plot = net_fig.add_subplot(111)\n",
    "# net_plot.grid()\n",
    "net_fig_agg = draw_figure(net_canvas, net_fig)\n",
    "\n",
    "# loss canvas\n",
    "loss_canvas_elem = window['loss_canvas']\n",
    "loss_canvas = loss_canvas_elem.TKCanvas\n",
    "\n",
    "loss_fig = plt.figure(figsize=(4,4))\n",
    "loss_plot = loss_fig.add_subplot(111)\n",
    "# loss_plot.grid()\n",
    "loss_fig_agg = draw_figure(loss_canvas, loss_fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "draw_signal = queue.Queue()\n",
    "stop_training = queue.Queue()\n",
    "\n",
    "# =======\n",
    "model = ''\n",
    "criterion = ''\n",
    "optimizer = ''\n",
    "epochs = ''\n",
    "\n",
    "losses = []\n",
    "\n",
    "data_points = 0\n",
    "data = ''\n",
    "#===========\n",
    "while 1:\n",
    "    event, values = window.read(timeout = 100)    \n",
    "    if event == 'Exit':\n",
    "        stop_training.put(1)\n",
    "        window.close()\n",
    "        break\n",
    "    elif event == 'optimizer':\n",
    "        \n",
    "         window['optimizer_params'].update( values= list( optimizer_parameter_dict[ values['optimizer'] ] ) ) \n",
    "\n",
    "    elif event == 'optimizer_params':\n",
    "        \n",
    "        current_param_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']])\n",
    "        window['param_type'].update(current_param_type if current_param_type != int else float)\n",
    "        param_value = optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']]\n",
    "        window['param_value'].update( param_value if current_param_type != int else float(param_value) )\n",
    "       \n",
    "        \n",
    "    elif event == 'update':\n",
    "        current_param_type = type( optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] )\n",
    "        new_value = ''\n",
    "        if current_param_type == tuple:\n",
    "            indiv_type = type(optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']][0])\n",
    "            if len(values['param_value'].split()) != 2:\n",
    "                print('incorrect input')\n",
    "            else:\n",
    "                new_value = ( indiv_type(values['param_value'].split()[0]) , indiv_type(values['param_value'].split()[1]) )\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "        else:\n",
    "            try:\n",
    "                new_value = current_param_type(values['param_value'])\n",
    "                optimizer_parameter_dict[ values['optimizer'] ][values['optimizer_params']] = new_value\n",
    "            except:\n",
    "                print('incorrect input')\n",
    "                \n",
    "#         \n",
    "        \n",
    "    elif event == 'gen_data':\n",
    "        \n",
    "        net_plot.cla()                    # clear the subplot\n",
    "#         net_plot.grid()                   # draw the grid\n",
    "        \n",
    "        data_points = int(values['data_slider']) # draw this many data points (on next line)\n",
    "        noise =  float(values['noise_slider'])\n",
    "        num_clusters = int(values['cluster_slider'])\n",
    "        \n",
    "        data = Dataset(num_data_points = data_points, num_clusters = num_clusters , cluster_std = noise)\n",
    "        X,y = data.get_all_data()\n",
    "        \n",
    "        colors = cm.seismic(np.linspace(0, 1, data.clusters))\n",
    "        for i,c in zip(range(data.clusters),colors):\n",
    "            net_plot.scatter(X[y==i,0],X[y==i,1],color = c )\n",
    "        \n",
    "        net_fig_agg.draw()\n",
    "        window['train_net'].update(disabled = False)\n",
    "        \n",
    "        \n",
    "    elif event == 'train_net':\n",
    "        losses = []\n",
    "        t1 = threading.Thread(target=train_network , args = (draw_signal,stop_training) , daemon = True)\n",
    "        t1.start()\n",
    "        window['stop_training'].update(disabled = False)\n",
    "    elif event =='stop_training':  \n",
    "        stop_training.put(1)\n",
    "        window['stop_training'].update(disabled = True)\n",
    "        \n",
    "            \n",
    "    try:\n",
    "        draw_status = draw_signal.get_nowait()\n",
    "    except queue.Empty:\n",
    "        draw_status = None\n",
    "    \n",
    "    if draw_status:\n",
    "        \n",
    "        net_fig_agg.flush_events()\n",
    "        net_fig_agg.draw()\n",
    "    \n",
    "        loss_fig_agg.flush_events()\n",
    "        loss_fig_agg.draw()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
