{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Beginner Template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some notes:\n",
    "* torch.Tensor returns a float Tensor where as torch.tensor infers the type, \n",
    "* the forward function requires the data as float tensors\n",
    "* when using CrossEntropyLoss the loss function requires the target values as long tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets as gen_dataset\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  same as before create data set\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, num_data_points = 100, num_clusters= 1 , cluster_std = 0.1):\n",
    "#         generate random clusters of data in machine learning/ AI we use X as input features or data we want to use to predict\n",
    "#         y is the target values , or the values we want to predict\n",
    "        self.clusters = num_clusters\n",
    "        centers = [[np.random.randn(),np.random.randn()] for i in range(num_clusters) ]\n",
    "        self.X,self.y = gen_dataset.make_blobs(n_samples=num_data_points,random_state=1,centers=centers,cluster_std=cluster_std)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x_data = torch.tensor(self.X[i]).float()\n",
    "        y_data = torch.tensor(self.y[i])\n",
    "        \n",
    "        return x_data,y_data\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.X,self.y\n",
    "    \n",
    "    def visualize(self):\n",
    "        plt.figure()\n",
    "        for i in range(self.clusters):\n",
    "            plt.scatter(self.X[self.y==i,0],self.X[self.y==i,1] )\n",
    "        plt.show()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size = 1 , output_size = 1, num_layers = 1, width = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,width)\n",
    "        self.hidden_layer = nn.Linear(width,width)\n",
    "        self.output_layer = nn.Linear(width,output_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.binary = True if self.output_size < 3 else False\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.hidden_layer(x))\n",
    "            \n",
    "        pred = torch.sigmoid(self.output_layer(x)) if self.binary else self.output_layer(x)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        if pred.shape[1] > 2:\n",
    "            return np.argmax(pred.data.numpy(),axis=1)\n",
    "        else:\n",
    "            return np.round(pred.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(num_data_points = 100, num_clusters= 2, cluster_std=0.7 )\n",
    "data_loader = DataLoader(data ,100)\n",
    "# data.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "output_size = data.clusters if data.clusters > 2 else 1\n",
    "\n",
    "model = my_model(input_size = 2 ,output_size = output_size, num_layers = 2, width = 4)\n",
    "\n",
    "if output_size  > 2:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.1)\n",
    "\n",
    "epochs = 2000\n",
    "losses = []\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(epochs):\n",
    "  \n",
    "    for x,y in data_loader:\n",
    "       \n",
    "        y_pred = model.forward(x)\n",
    "\n",
    "        if output_size > 2:\n",
    "            loss = criterion( y_pred, y )\n",
    "        else:\n",
    "            loss = criterion( y_pred.view(-1),y.float())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(f'epoch:{i} loss:{loss.item()}')\n",
    "#         y_pred = model.predict(x)\n",
    "            \n",
    "    if i%10 == 0:\n",
    "                \n",
    "        X = x.numpy()\n",
    "        y = y.numpy()\n",
    "       \n",
    "        ax[0].cla()\n",
    "        ax[0].set_title(f'epoch:{i}')\n",
    "        h = 0.02\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "       \n",
    "        Z = np.array(model.predict(torch.Tensor(np.c_[xx.ravel(), yy.ravel()])))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        ax[0].imshow(Z, interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,\n",
    "        aspect='auto', origin='lower')\n",
    "\n",
    "        for i in range(data.clusters):\n",
    "            ax[0].scatter(X[y==i,0],X[y==i,1] )\n",
    "       \n",
    "        ax[1].cla()\n",
    "        ax[1].set_title(f'loss:{round(loss.item(),4)}')\n",
    "        ax[1].plot(np.array(losses)/len(losses) )\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
